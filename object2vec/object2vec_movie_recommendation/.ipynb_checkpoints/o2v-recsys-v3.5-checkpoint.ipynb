{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Amazon confidential</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to SageMaker ObjectToVec model for MovieLens recommendation\n",
    "\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Data exploration and preparation](#Data-exploration-and-preparation)\n",
    "1. [Rating prediction task](#Rating-prediction-task)\n",
    "1. [Recommendation task](#Recommendation-task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "### ObjectToVec\n",
    "*Object2Vec* is a highly customizable multi-purpose algorithm that can learn embeddings of pairs of objects. The embeddings are learned such that it preserves their pairwise **similarities** in the original space.\n",
    "- **Similarity** is user-defined: users need to provide the algorithm with pairs of objects that they define as similar (1) or dissimilar (0); alternatively, the users can define similarity in a continuous sense (provide a real-valued similarity score)\n",
    "- The learned embeddings can be used to efficiently compute nearest neighbors of objects, as well as to visualize natural clusters of related objects in the embedding space. In addition, the embeddings can also be used as features of the corresponding objects in downstream supervised tasks such as classification or regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Object2Vec architecture](image_o2v/image.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook example:\n",
    "We demonstrate how Object2Vec can be used to solve problems arising in recommendation systems. Specifically,\n",
    "- We provide the algorithm with (userID, movieID) pairs; for each such pair, we also provide a \"label\" that tells the algorithm whether this user and movie are similar or not\n",
    "     * When the labels are real-valued, we use the algorithm to predict the exact ratings of a movie given a user\n",
    "     * When the labels are binary, we use the algorithm to recommendation movies to users\n",
    "\n",
    "### Dataset\n",
    "- We use the MovieLens 100k dataset: https://grouplens.org/datasets/movielens/100k/\n",
    "\n",
    "\n",
    "### Use cases\n",
    "\n",
    "- Task 1: Rating prediction (regression)\n",
    "- Task 2: Movie recommendation (classification)\n",
    "- Task 3: Visualization of learned movie embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jsonlines) (1.11.0)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-1.2.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv, jsonlines\n",
    "import numpy as np\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-100k.zip\n",
      "  inflating: k.zip                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100 4808k  100 4808k    0     0  7134k      0 --:--:-- --:--:-- --:--:-- 7123k\n",
      "replace ml-100k/allbut.pl? [y]es, [n]o, [A]ll, [N]one, [r]ename: new name: replace ml-100k/mku.sh? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n",
      "(EOF or read error, treating as \"[N]one\" ...)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -o ml-100k.zip http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "unzip ml-100k.zip\n",
    "rm ml-100k.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create some utility functions for data exploration and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some utility functions\n",
    "\n",
    "def load_csv_data(filename, delimiter):\n",
    "    \"\"\"\n",
    "    input: a file readable as csv and separated by a delimiter\n",
    "    and has format users - movies - ratings - etc\n",
    "    output: a list, where each row of the list is of the form\n",
    "    {'in0':userID, 'in1':movieID, 'label':rating}\n",
    "    \"\"\"\n",
    "    to_data_list = list()\n",
    "    users = list()\n",
    "    movies = list()\n",
    "    ratings = list()\n",
    "    unique_users = set()\n",
    "    unique_movies = set()\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=delimiter)\n",
    "        for count, row in enumerate(reader):\n",
    "            #if count!=0:\n",
    "            to_data_list.append({'in0':[int(row[0])], 'in1':[int(row[1])], 'label':float(row[2])})\n",
    "            users.append(row[0])\n",
    "            movies.append(row[1])\n",
    "            ratings.append(float(row[2]))\n",
    "            unique_users.add(row[0])\n",
    "            unique_movies.add(row[1])\n",
    "    print(\"In file {}, there are {} ratings\".format(filename, len(ratings)))\n",
    "    print(\"The ratings have mean: {}, median: {}, and variance: {}\".format(\n",
    "                                        round(np.mean(ratings), 2), \n",
    "                                        round(np.median(ratings), 2), \n",
    "                                        round(np.var(ratings), 2)))\n",
    "    print(\"There are {} unique users and {} unique movies\".format(len(unique_users), len(unique_movies)))\n",
    "    return to_data_list\n",
    "\n",
    "\n",
    "def csv_to_augmented_data_dict(filename, delimiter):\n",
    "    \"\"\"\n",
    "    Input: a file that must be readable as csv and separated by delimiter (to make columns)\n",
    "    has format users - movies - ratings - etc\n",
    "    Output:\n",
    "      Users dictionary: keys as user ID's; each key corresponds to a list of movie ratings by that user\n",
    "      Movies dictionary: keys as movie ID's; each key corresponds a list of ratings of that movie by different users\n",
    "    \"\"\"\n",
    "    to_users_dict = dict() \n",
    "    to_movies_dict = dict()\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=delimiter)\n",
    "        for count, row in enumerate(reader):\n",
    "            #if count!=0:\n",
    "            if row[0] not in to_users_dict:\n",
    "                to_users_dict[row[0]] = [(row[1], row[2])]\n",
    "            else:\n",
    "                to_users_dict[row[0]].append((row[1], row[2]))\n",
    "            if row[1] not in to_movies_dict:\n",
    "                to_movies_dict[row[1]] = list(row[0])\n",
    "            else:\n",
    "                to_movies_dict[row[1]].append(row[0])\n",
    "    return to_users_dict, to_movies_dict\n",
    "\n",
    "\n",
    "def user_dict_to_data_list(user_dict):\n",
    "    # turn user_dict format to data list format (acceptable to the algorithm)\n",
    "    data_list = list()\n",
    "    for user, movie_rating_list in user_dict.items():\n",
    "        for movie, rating in movie_rating_list:\n",
    "            data_list.append({'in0':[int(user)], 'in1':[int(movie)], 'label':float(rating)})\n",
    "    return data_list\n",
    "\n",
    "def divide_user_dicts(user_dict, sp_ratio_dict):\n",
    "    \"\"\"\n",
    "    Input: A user dictionary, a ration dictionary\n",
    "         - format of sp_ratio_dict = {'train':0.8, \"test\":0.2}\n",
    "    Output: \n",
    "        A dictionary of dictionaries, with key corresponding to key provided by sp_ratio_dict\n",
    "        and each key corresponds to a subdivded user dictionary\n",
    "    \"\"\"\n",
    "    ratios = [val for _, val in sp_ratio_dict.items()]\n",
    "    assert np.sum(ratios) == 1, \"the sampling ratios must sum to 1!\"\n",
    "    divided_dict = {}\n",
    "    for user, movie_rating_list in user_dict.items():\n",
    "        sub_movies_ptr = 0\n",
    "        sub_movies_list = []\n",
    "        #movie_list, _ = zip(*movie_rating_list)\n",
    "        #print(movie_list)\n",
    "        for i, ratio in enumerate(ratios):\n",
    "            if i < len(ratios)-1:\n",
    "                sub_movies_ptr_end = sub_movies_ptr + int(len(movie_rating_list)*ratio)\n",
    "                sub_movies_list.append(movie_rating_list[sub_movies_ptr:sub_movies_ptr_end])\n",
    "                sub_movies_ptr = sub_movies_ptr_end\n",
    "            else:\n",
    "                sub_movies_list.append(movie_rating_list[sub_movies_ptr:])\n",
    "        for subset_name in sp_ratio_dict.keys():\n",
    "            if subset_name not in divided_dict:\n",
    "                divided_dict[subset_name] = {user: sub_movies_list.pop(0)}\n",
    "            else:\n",
    "                #access sub-dictionary\n",
    "                divided_dict[subset_name][user] = sub_movies_list.pop(0)\n",
    "    \n",
    "    return divided_dict\n",
    "\n",
    "def write_csv_to_jsonl(jsonl_fname, csv_fname, csv_delimiter):\n",
    "    \"\"\"\n",
    "    Input: a file readable as csv and separated by delimiter (to make columns)\n",
    "        - has format users - movies - ratings - etc\n",
    "    Output: a jsonline file converted from the csv file\n",
    "    \"\"\"\n",
    "    with jsonlines.open(jsonl_fname, mode='w') as writer:\n",
    "        with open(csv_fname, 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=csv_delimiter)\n",
    "            for count, row in enumerate(reader):\n",
    "                #print(row)\n",
    "                #if count!=0:\n",
    "                writer.write({'in0':[int(row[0])], 'in1':[int(row[1])], 'label':float(row[2])})\n",
    "        print('Created {} jsonline file'.format(jsonl_fname))\n",
    "                    \n",
    "    \n",
    "def write_data_list_to_jsonl(data_list, to_fname):\n",
    "    \"\"\"\n",
    "    Input: a data list, where each row of the list is a Python dictionary taking form\n",
    "    {'in0':userID, 'in1':movieID, 'label':rating}\n",
    "    Output: save the list as a jsonline file\n",
    "    \"\"\"\n",
    "    with jsonlines.open(to_fname, mode='w') as writer:\n",
    "        for row in data_list:\n",
    "            #print(row)\n",
    "            writer.write({'in0':row['in0'], 'in1':row['in1'], 'label':row['label']})\n",
    "    print(\"Created {} jsonline file\".format(to_fname))\n",
    "\n",
    "def data_list_to_inference_format(data_list, binarize=True, label_thres=3):\n",
    "    \"\"\"\n",
    "    Input: a data list\n",
    "    Output: test data and label, acceptable by SageMaker for inference\n",
    "    \"\"\"\n",
    "    data_ = [({\"in0\":row['in0'], 'in1':row['in1']}, row['label']) for row in data_list]\n",
    "    data, label = zip(*data_)\n",
    "    infer_data = {\"instances\":data}\n",
    "    if binarize:\n",
    "        label = get_binarized_label(list(label), label_thres)\n",
    "    return infer_data, label\n",
    "\n",
    "\n",
    "def get_binarized_label(data_list, thres):\n",
    "    \"\"\"\n",
    "    Input: data list\n",
    "    Output: a binarized data list for recommendation task\n",
    "    \"\"\"\n",
    "    for i, row in enumerate(data_list):\n",
    "        if type(row) is dict:\n",
    "            #if i < 10:\n",
    "                #print(row['label'])\n",
    "            if row['label'] > thres:\n",
    "                #print(row)\n",
    "                data_list[i]['label'] = 1\n",
    "            else:\n",
    "                data_list[i]['label'] = 0\n",
    "        else:\n",
    "            if row > thres:\n",
    "                data_list[i] = 1\n",
    "            else:\n",
    "                data_list[i] = 0\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In file ml-100k/ua.base, there are 90570 ratings\n",
      "The ratings have mean: 3.52, median: 4.0, and variance: 1.27\n",
      "There are 943 unique users and 1680 unique movies\n",
      "In file ml-100k/ua.test, there are 9430 ratings\n",
      "The ratings have mean: 3.59, median: 4.0, and variance: 1.25\n",
      "There are 943 unique users and 1129 unique movies\n"
     ]
    }
   ],
   "source": [
    "## Load data and shuffle\n",
    "prefix = 'ml-100k'\n",
    "train_path = os.path.join(prefix, 'ua.base')\n",
    "valid_path = os.path.join(prefix, 'ua.test')\n",
    "test_path = os.path.join(prefix, 'ub.test')\n",
    "\n",
    "train_data_list = load_csv_data(train_path, '\\t')\n",
    "random.shuffle(train_data_list)\n",
    "validation_data_list = load_csv_data(valid_path, '\\t')\n",
    "random.shuffle(validation_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_users_dict, to_movies_dict = csv_to_augmented_data_dict(train_path, '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We perform some data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min, max, and median 'movies per user' is 10, 727, and 55.0\n",
      "The min, max, and median 'users per movie' is 1, 495, and 25.0\n",
      "In the training set\n",
      "There are 213 users with no more than 20 movies\n",
      "There are 12 movies with no more than 2 user\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Users per movie')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Calculate min, max, median of number of movies per user\n",
    "movies_per_user = [len(val) for key, val in to_users_dict.items()]\n",
    "\n",
    "print(\"The min, max, and median 'movies per user' is {}, {}, and {}\".format(np.amin(movies_per_user),\n",
    "                                                                         np.amax(movies_per_user),\n",
    "                                                                         np.median(movies_per_user)))\n",
    "users_per_movie = [len(val) for key, val in to_movies_dict.items()]\n",
    "print(\"The min, max, and median 'users per movie' is {}, {}, and {}\".format(np.amin(users_per_movie),\n",
    "                                                                         np.amax(users_per_movie),\n",
    "                                                                          np.median(users_per_movie)))\n",
    "\n",
    "\n",
    "count = 0\n",
    "n_movies_lower_bound = 20\n",
    "for n_movies in movies_per_user:\n",
    "    if n_movies <= n_movies_lower_bound:\n",
    "        count += 1\n",
    "print(\"In the training set\")\n",
    "print('There are {} users with no more than {} movies'.format(count, n_movies_lower_bound))\n",
    "#\n",
    "count = 0\n",
    "n_users_lower_bound = 2\n",
    "for n_users in users_per_movie:\n",
    "    if n_users <= n_users_lower_bound:\n",
    "        count += 1\n",
    "print('There are {} movies with no more than {} user'.format(count, n_users_lower_bound))\n",
    "\n",
    "\n",
    "## figures\n",
    "\n",
    "f = plt.figure(1)\n",
    "plt.hist(movies_per_user)\n",
    "plt.title(\"Movies per user\")\n",
    "##\n",
    "g = plt.figure(2)\n",
    "plt.hist(users_per_movie)\n",
    "plt.title(\"Users per movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of movies with an extremely small number of users (<3) is neglible compared to the total number of movies, we will not remove movies from the dataset (same applies for users) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train_r.jsonl jsonline file\n",
      "Created validation_r.jsonl jsonline file\n"
     ]
    }
   ],
   "source": [
    "## Save training and validation data locally for rating-prediction (regression) task\n",
    "\n",
    "write_data_list_to_jsonl(copy.deepcopy(train_data_list), 'train_r.jsonl')\n",
    "write_data_list_to_jsonl(copy.deepcopy(validation_data_list), 'validation_r.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train_c.jsonl jsonline file\n",
      "Created validation_c.jsonl jsonline file\n"
     ]
    }
   ],
   "source": [
    "## Save training and validation data locally for recommendation (classification) task\n",
    "\n",
    "### binarize the data \n",
    "\n",
    "train_c = get_binarized_label(copy.deepcopy(train_data_list), 3.0)\n",
    "valid_c = get_binarized_label(copy.deepcopy(validation_data_list), 3.0)\n",
    "\n",
    "write_data_list_to_jsonl(train_c, 'train_c.jsonl')\n",
    "write_data_list_to_jsonl(valid_c, 'validation_c.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We check whether the two classes are balanced after binarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0.5510213094843768 fraction of positive ratings in train_c.jsonl\n",
      "There are 0.5799575821845175 fraction of positive ratings in validation_c.jsonl\n"
     ]
    }
   ],
   "source": [
    "train_c_label = [row['label'] for row in train_c]\n",
    "valid_c_label = [row['label'] for row in valid_c]\n",
    "\n",
    "print(\"There are {} fraction of positive ratings in train_c.jsonl\".format(\n",
    "                                np.count_nonzero(train_c_label)/len(train_c_label)))\n",
    "print(\"There are {} fraction of positive ratings in validation_c.jsonl\".format(\n",
    "                                np.sum(valid_c_label)/len(valid_c_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating prediction task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse_loss(res, labels):\n",
    "    if type(res) is dict:\n",
    "        res = res['predictions']\n",
    "    assert len(res)==len(labels), 'result and label length mismatch!'\n",
    "    loss = 0\n",
    "    for row, label in zip(res, labels):\n",
    "        if type(row)is dict:\n",
    "            loss += (row['scores'][0]-label)**2\n",
    "        else:\n",
    "            loss += (row-label)**2\n",
    "    return round(loss/float(len(labels)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_r_data, valid_r_label = data_list_to_inference_format(copy.deepcopy(validation_data_list), binarize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first do a sanity check to see how do two baselines work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1\n",
    "\n",
    "A naive approach to predict movie ratings on unseen data is to use the global average of the user predictions in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Baseline 1 (global rating average) prediction is 3.52\n",
      "The validation mse loss of the Baseline 1 is 1.26\n"
     ]
    }
   ],
   "source": [
    "train_r_label = [row['label'] for row in copy.deepcopy(train_data_list)]\n",
    "\n",
    "bs1_prediction = round(np.mean(train_r_label), 2)\n",
    "print('The Baseline 1 (global rating average) prediction is {}'.format(bs1_prediction))\n",
    "print(\"The validation mse loss of the Baseline 1 is {}\".format(\n",
    "                                     get_mse_loss(len(valid_r_label)*[bs1_prediction], valid_r_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use a better baseline, which is to predict based on the user-averaged ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bs2_predictor(test_data, user_dict, is_classification=False, thres=3):\n",
    "    test_data = copy.deepcopy(test_data['instances'])\n",
    "    predictions = list()\n",
    "    for row in test_data:\n",
    "        userID = str(row[\"in0\"][0])\n",
    "        # predict movie ID based on local average of user's prediction\n",
    "        local_movies, local_ratings = zip(*user_dict[userID])\n",
    "        local_ratings = [float(score) for score in local_ratings]\n",
    "        predictions.append(np.mean(local_ratings))\n",
    "        if is_classification:\n",
    "            predictions[-1] = int(predictions[-1] > 3)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation loss of the Baseline 2 (user-based rating average) is 1.09\n"
     ]
    }
   ],
   "source": [
    "bs2_prediction = bs2_predictor(valid_r_data, to_users_dict, is_classification=False)\n",
    "print(\"The validation loss of the Baseline 2 (user-based rating average) is {}\".format(\n",
    "                                     get_mse_loss(bs2_prediction, valid_r_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use *Object2Vec* to predict the movie ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define S3 bucket that hosts data and model, and upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "import os\n",
    " \n",
    "bucket = '<Your bucket name>'\n",
    "input_prefix = 'object2vec/movielens/input'\n",
    "output_prefix = 'object2vec/movielens/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data to S3 and make data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import s3_input\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "input_paths = {}\n",
    "output_path = os.path.join('s3://', bucket, output_prefix)\n",
    "\n",
    "for data_name in ['train', 'validation']:\n",
    "    pre_key = os.path.join(input_prefix, 'rating', f'{data_name}')\n",
    "    fname = '{}_r.jsonl'.format(data_name)\n",
    "    data_path = os.path.join('s3://', bucket, pre_key, fname)\n",
    "    s3_client.upload_file(fname, bucket, os.path.join(pre_key, fname))\n",
    "    input_paths[data_name] = s3_input(data_path, distribution='ShardedByS3Key', content_type='application/jsonlines')\n",
    "    print('Uploaded data to {}'.format(data_path))\n",
    "\n",
    "print('Trained model will be saved at', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!aws s3 ls \"s3://$bucket/object2vec/movielens/small/rating/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ObjectToVec algorithm image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "## Get docker image of ObjectToVec algorithm\n",
    "container = '174872318107.dkr.ecr.us-west-2.amazonaws.com/object2vec:latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first define training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"_kvstore\": \"device\",\n",
    "    \"_num_gpus\": \"auto\",\n",
    "    \"_num_kv_servers\": \"auto\",\n",
    "    \"bucket_width\": 0,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_tolerance\": 0.01,\n",
    "    \"enc0_cnn_filter_width\": 3,\n",
    "    \"enc0_layers\": \"auto\",\n",
    "    \"enc0_max_seq_len\": 1,\n",
    "    \"enc0_network\": \"pooled_embedding\",\n",
    "    \"enc0_token_embedding_dim\": 300,\n",
    "    \"enc0_vocab_size\": 944,\n",
    "    \"enc1_layers\": \"auto\",\n",
    "    \"enc1_max_seq_len\": 1,\n",
    "    \"enc1_network\": \"pooled_embedding\",\n",
    "    \"enc1_token_embedding_dim\": 300,\n",
    "    \"enc1_vocab_size\": 1684,\n",
    "    \"enc_dim\": 1024,\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"mini_batch_size\": 64,\n",
    "    \"mlp_activation\": \"tanh\",\n",
    "    \"mlp_dim\": 256,\n",
    "    \"mlp_layers\": 1,\n",
    "    \"num_classes\": 2,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"output_layer\": \"mean_squared_error\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: object2vec-2018-10-17-14-53-09-989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-17 14:53:10 Starting - Starting the training job...\n",
      "2018-10-17 14:53:11 Starting - Launching requested ML instances......\n",
      "2018-10-17 14:54:36 Starting - Preparing the instances for training......\n",
      "2018-10-17 14:55:40 Downloading - Downloading input data\n",
      "2018-10-17 14:55:40 Training - Downloading the training image.........\n",
      "2018-10-17 14:57:02 Training - Training image download completed. Training in progress.\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'output_layer': u'softmax', u'enc1:freeze_pretrained_embedding': u'true', u'enc1:vocab_file': u'', u'enc0:vocab_file': u'', u'epochs': 20, u'mlp_dim': 512, u'enc0:token_embedding_dim': 300, u'enc0:network': u'hcnn', u'_num_kv_servers': u'auto', u'mlp_layers': 2, u'enc0:layers': u'auto', u'weight_decay': 0, u'enc1:layers': u'auto', u'learning_rate': 0.0004, u'negative_sampling_rate': 0, u'num_classes': 2, u'enc0:cnn_filter_width': 3, u'early_stopping_patience': 3, u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': 0.01, u'dropout': 0, u'bucket_width': 0, u'enc_dim': 4096, u'enc1:cnn_filter_width': 3, u'enc0:freeze_pretrained_embedding': u'true', u'mini_batch_size': 32, u'enc1:network': u'enc0', u'enc1:pretrained_embedding_file': u'', u'enc1:token_embedding_dim': 300, u'_num_gpus': u'auto', u'mlp_activation': u'linear', u'_kvstore': u'auto_gpu', u'enc0:pretrained_embedding_file': u''}\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'output_layer': u'mean_squared_error', u'epochs': u'20', u'mlp_dim': u'256', u'enc0:token_embedding_dim': u'300', u'enc0:network': u'pooled_embedding', u'_num_kv_servers': u'auto', u'mlp_layers': u'1', u'enc0:layers': u'auto', u'enc1:layers': u'auto', u'enc0:max_seq_len': u'1', u'enc0:cnn_filter_width': u'3', u'early_stopping_patience': u'3', u'enc0:vocab_size': u'944', u'optimizer': u'adam', u'early_stopping_tolerance': u'0.01', u'learning_rate': u'0.001', u'bucket_width': u'0', u'enc_dim': u'1024', u'mini_batch_size': u'64', u'enc1:network': u'pooled_embedding', u'num_classes': u'2', u'enc1:token_embedding_dim': u'300', u'_num_gpus': u'auto', u'enc1:max_seq_len': u'1', u'mlp_activation': u'tanh', u'enc1:vocab_size': u'1684', u'_kvstore': u'device'}\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] Final configuration: {u'output_layer': u'mean_squared_error', u'enc1:freeze_pretrained_embedding': u'true', u'enc1:vocab_file': u'', u'enc0:vocab_file': u'', u'epochs': u'20', u'mlp_dim': u'256', u'enc0:token_embedding_dim': u'300', u'enc0:network': u'pooled_embedding', u'_num_kv_servers': u'auto', u'mlp_layers': u'1', u'enc0:layers': u'auto', u'weight_decay': 0, u'enc1:layers': u'auto', u'learning_rate': u'0.001', u'enc0:max_seq_len': u'1', u'negative_sampling_rate': 0, u'num_classes': u'2', u'enc0:cnn_filter_width': u'3', u'early_stopping_patience': u'3', u'enc0:vocab_size': u'944', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'1024', u'enc1:cnn_filter_width': 3, u'enc0:freeze_pretrained_embedding': u'true', u'mini_batch_size': u'64', u'enc1:network': u'pooled_embedding', u'enc1:pretrained_embedding_file': u'', u'enc1:token_embedding_dim': u'300', u'_num_gpus': u'auto', u'enc1:max_seq_len': u'1', u'mlp_activation': u'tanh', u'enc1:vocab_size': u'1684', u'_kvstore': u'device', u'enc0:pretrained_embedding_file': u''}\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] Using default worker.\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] create_iter params {u'output_layer': u'mean_squared_error', u'enc1:freeze_pretrained_embedding': u'true', u'enc1:vocab_file': u'', u'enc0:vocab_file': u'', u'epochs': u'20', u'mlp_dim': u'256', u'enc0:token_embedding_dim': u'300', u'enc0:network': u'pooled_embedding', u'_num_kv_servers': u'auto', u'mlp_layers': u'1', u'enc0:layers': u'auto', u'weight_decay': 0, u'enc1:layers': u'auto', u'learning_rate': u'0.001', u'enc0:max_seq_len': u'1', u'negative_sampling_rate': 0, u'num_classes': u'2', u'enc0:cnn_filter_width': u'3', u'early_stopping_patience': u'3', u'enc0:vocab_size': u'944', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'1024', u'enc1:cnn_filter_width': 3, u'enc0:freeze_pretrained_embedding': u'true', u'mini_batch_size': u'64', u'enc1:network': u'pooled_embedding', u'enc1:pretrained_embedding_file': u'', u'enc1:token_embedding_dim': u'300', u'_num_gpus': u'auto', u'enc1:max_seq_len': u'1', u'mlp_activation': u'tanh', u'enc1:vocab_size': u'1684', u'_kvstore': u'device', u'enc0:pretrained_embedding_file': u''}\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] create_iter content_params {}\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] Config: {'epochs': 20, 'mini_batch_size': 64, 'optimizer': 'adam', 'output_layer': 'mean_squared_error', 'mlp_dim': 256, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 1024, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'num_classes': None}\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] use bucketing: False\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:05 INFO 140033525749568] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Source words: 90570\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Target words: 90570\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Total: 90570 samples in 1 buckets\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Bucket of (1, 1) : 90570 samples in 1415 batches of 64, approx 64.0 words/batch\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] fill up mode: replicate\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Replicating 54 random sentences from bucket (1, 1) to size it to multiple of 64\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Bucket batch sizes: [BucketBatchSize(batch_size=64, average_words_per_batch=64)]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] create_iter params {u'output_layer': u'mean_squared_error', u'enc1:freeze_pretrained_embedding': u'true', u'enc1:vocab_file': u'', u'enc0:vocab_file': u'', u'epochs': u'20', u'mlp_dim': u'256', u'enc0:token_embedding_dim': u'300', u'enc0:network': u'pooled_embedding', u'_num_kv_servers': u'auto', u'mlp_layers': u'1', u'enc0:layers': u'auto', u'weight_decay': 0, u'enc1:layers': u'auto', u'learning_rate': u'0.001', u'enc0:max_seq_len': u'1', u'negative_sampling_rate': 0, u'num_classes': u'2', u'enc0:cnn_filter_width': u'3', u'early_stopping_patience': u'3', u'enc0:vocab_size': u'944', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'1024', u'enc1:cnn_filter_width': 3, u'enc0:freeze_pretrained_embedding': u'true', u'mini_batch_size': u'64', u'enc1:network': u'pooled_embedding', u'enc1:pretrained_embedding_file': u'', u'enc1:token_embedding_dim': u'300', u'_num_gpus': u'auto', u'enc1:max_seq_len': u'1', u'mlp_activation': u'tanh', u'enc1:vocab_size': u'1684', u'_kvstore': u'device', u'enc0:pretrained_embedding_file': u''}\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] create_iter content_params {}\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Config: {'epochs': 20, 'mini_batch_size': 64, 'optimizer': 'adam', 'output_layer': 'mean_squared_error', 'mlp_dim': 256, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 1024, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'num_classes': None}\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] use bucketing: False\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Source words: 9430\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Target words: 9430\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Total: 9430 samples in 1 buckets\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Bucket of (1, 1) : 9430 samples in 147 batches of 64, approx 64.0 words/batch\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] fill up mode: replicate\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Replicating 42 random sentences from bucket (1, 1) to size it to multiple of 64\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': 3, u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Config: {'epochs': 20, 'mini_batch_size': 64, 'optimizer': 'adam', 'output_layer': 'mean_squared_error', 'mlp_dim': 256, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 1024, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 1024, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'num_classes': None}\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Creating new state\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] params {u'output_layer': u'mean_squared_error', u'enc1:freeze_pretrained_embedding': u'true', u'enc1:vocab_file': u'', u'enc0:vocab_file': u'', u'epochs': u'20', u'mlp_dim': u'256', u'enc0:token_embedding_dim': u'300', u'enc0:network': u'pooled_embedding', u'_num_kv_servers': u'auto', u'mlp_layers': u'1', u'enc0:layers': u'auto', u'weight_decay': 0, u'enc1:layers': u'auto', u'learning_rate': u'0.001', u'enc0:max_seq_len': u'1', u'negative_sampling_rate': 0, u'num_classes': u'2', u'enc0:cnn_filter_width': u'3', u'early_stopping_patience': u'3', u'enc0:vocab_size': u'944', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'1024', 'default_bucket_key': (1, 1), u'enc1:cnn_filter_width': 3, u'enc0:freeze_pretrained_embedding': u'true', u'mini_batch_size': u'64', u'enc1:network': u'pooled_embedding', u'enc1:pretrained_embedding_file': u'', u'enc1:token_embedding_dim': u'300', u'_num_gpus': u'auto', u'enc1:max_seq_len': u'1', u'mlp_activation': u'tanh', u'enc1:vocab_size': u'1684', u'_kvstore': u'device', u'enc0:pretrained_embedding_file': u''}\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] nvidia-smi took: 0.0754859447479 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] context [gpu(0)]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Create Store: device\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[31m========================================================================================================================\u001b[0m\n",
      "\u001b[31msource(null)                                        1                       0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31membed_0(Embedding)                                  1x1024                  0           source                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_not_equal_scalar0(_not_equal_scalar)               1                       0           source                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mreshape0(Reshape)                                   1x1                     0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_mul0(broadcast_mul)                       1x1024                  0           embed_0                         \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum0(sum)                                           1024                    0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum1(sum)                                           1                       0           reshape0                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mzeros_like0(zeros_like)                             1                       0           sum1                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_equal0(_equal)                                     1                       0           sum1                            \n",
      "                                                                                        zeros_like0                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_plus0(elemwise_add)                                1                       0           sum1                            \n",
      "                                                                                        _equal0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_div0(broadcast_div)                       1024                    0           sum0                            \n",
      "                                                                                        _plus0                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout0(Dropout)                                   1024                    0           broadcast_div0                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31membed_1(Embedding)                                  1x1024                  0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_not_equal_scalar1(_not_equal_scalar)               1                       0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mreshape1(Reshape)                                   1x1                     0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_mul1(broadcast_mul)                       1x1024                  0           embed_1                         \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum2(sum)                                           1024                    0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum3(sum)                                           1                       0           reshape1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mzeros_like1(zeros_like)                             1                       0           sum3                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_equal1(_equal)                                     1                       0           sum3                            \n",
      "                                                                                        zeros_like1                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_plus1(elemwise_add)                                1                       0           sum3                            \n",
      "                                                                                        _equal1                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_div1(broadcast_div)                       1024                    0           sum2                            \n",
      "                                                                                        _plus1                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout1(Dropout)                                   1024                    0           broadcast_div1                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_mul0(elemwise_mul)                                 1024                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_minus0(elemwise_sub)                               1024                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mabs0(abs)                                           1024                    0           _minus0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconcat0(Concat)                                     4096                    0           _mul0                           \n",
      "                                                                                        dropout0                        \n",
      "                                                                                        dropout1                        \n",
      "                                                                                        abs0                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmlp_fc0(FullyConnected)                             256                     1048832     concat0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation0(Activation)                             256                     0           mlp_fc0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout2(Dropout)                                   256                     0           activation0                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31moutput_layer(FullyConnected)                        1                       257         dropout2                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mout_layer(LinearRegressionOutput)                   1                       0           output_layer                    \u001b[0m\n",
      "\u001b[31m========================================================================================================================\u001b[0m\n",
      "\u001b[31mTotal params: 1049089\u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] fixed_param_names: []\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:07 INFO 140033525749568] Initialized BucketingPlus Module\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/17/2018 14:57:11 INFO 140033525749568] arg_params keys for module initialization: []\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:11 INFO 140033525749568] all params:['output_layer_weight', 'mlp_fc0_weight', 'mlp_fc0_bias', 'output_layer_bias', 'embed_1_weight', 'embed_0_weight']\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 3735.6369495391846, \"sum\": 3735.6369495391846, \"min\": 3735.6369495391846}}, \"EndTime\": 1539788231.596803, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788225.763338}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1539788231.597036, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788231.596977}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:12 INFO 140033525749568] Epoch: 0, batches: 100, num_examples: 6400, 15066.4 samples/sec, epoch time so far: 0:00:00.424786\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:12 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.659 mean_absolute_error: 1.005 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:12 INFO 140033525749568] Epoch: 0, batches: 200, num_examples: 12800, 15425.8 samples/sec, epoch time so far: 0:00:00.829781\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:12 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.369 mean_absolute_error: 0.915 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:12 INFO 140033525749568] Epoch: 0, batches: 300, num_examples: 19200, 15628.0 samples/sec, epoch time so far: 0:00:01.228566\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:12 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.266 mean_absolute_error: 0.885 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:13 INFO 140033525749568] Epoch: 0, batches: 400, num_examples: 25600, 15713.9 samples/sec, epoch time so far: 0:00:01.629131\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:13 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.220 mean_absolute_error: 0.871 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:13 INFO 140033525749568] Epoch: 0, batches: 500, num_examples: 32000, 15743.6 samples/sec, epoch time so far: 0:00:02.032577\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:13 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.181 mean_absolute_error: 0.859 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:14 INFO 140033525749568] Epoch: 0, batches: 600, num_examples: 38400, 15781.8 samples/sec, epoch time so far: 0:00:02.433187\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:14 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.153 mean_absolute_error: 0.848 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:14 INFO 140033525749568] Epoch: 0, batches: 700, num_examples: 44800, 15790.9 samples/sec, epoch time so far: 0:00:02.837074\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:14 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.125 mean_absolute_error: 0.838 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:14 INFO 140033525749568] Epoch: 0, batches: 800, num_examples: 51200, 15822.2 samples/sec, epoch time so far: 0:00:03.235955\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:14 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.102 mean_absolute_error: 0.829 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:15 INFO 140033525749568] Epoch: 0, batches: 900, num_examples: 57600, 15848.0 samples/sec, epoch time so far: 0:00:03.634539\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:15 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.085 mean_absolute_error: 0.823 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:15 INFO 140033525749568] Epoch: 0, batches: 1000, num_examples: 64000, 15843.8 samples/sec, epoch time so far: 0:00:04.039440\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:15 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.068 mean_absolute_error: 0.817 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:16 INFO 140033525749568] Epoch: 0, batches: 1100, num_examples: 70400, 15860.0 samples/sec, epoch time so far: 0:00:04.438830\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:16 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.055 mean_absolute_error: 0.812 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:16 INFO 140033525749568] Epoch: 0, batches: 1200, num_examples: 76800, 15855.9 samples/sec, epoch time so far: 0:00:04.843617\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:16 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.044 mean_absolute_error: 0.808 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:16 INFO 140033525749568] Epoch: 0, batches: 1300, num_examples: 83200, 15808.9 samples/sec, epoch time so far: 0:00:05.262868\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:16 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.035 mean_absolute_error: 0.804 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:17 INFO 140033525749568] Epoch: 0, batches: 1400, num_examples: 89600, 15823.1 samples/sec, epoch time so far: 0:00:05.662615\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:17 INFO 140033525749568] #011Training metrics: mean_squared_error: 1.027 mean_absolute_error: 0.801 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:17 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:17 INFO 140033525749568] Completed Epoch: 0, time taken: 0:00:05.727258\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:17 INFO 140033525749568] Epoch 0 Training metrics:   mean_squared_error: 1.025 mean_absolute_error: 0.800 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:17 INFO 140033525749568] #quality_metric: host=algo-1, epoch=0, train mean_squared_error <loss>=1.02490783079\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:17 INFO 140033525749568] Epoch 0 Validation metrics: mean_squared_error: 0.951 mean_absolute_error: 0.772 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:17 INFO 140033525749568] #quality_metric: host=algo-1, epoch=0, validation mean_squared_error <loss>=0.951027070348\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:17 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}, \"early_stop.time\": {\"count\": 1, \"max\": 0.4470348358154297, \"sum\": 0.4470348358154297, \"min\": 0.4470348358154297}, \"update.time\": {\"count\": 1, \"max\": 5917.337894439697, \"sum\": 5917.337894439697, \"min\": 5917.337894439697}}, \"EndTime\": 1539788237.584867, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788231.596922}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:17 INFO 140033525749568] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Total Records Seen\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1539788237.585159, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 0}, \"StartTime\": 1539788231.667501}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:17 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15313.7417994 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:18 INFO 140033525749568] Epoch: 1, batches: 100, num_examples: 6400, 15981.1 samples/sec, epoch time so far: 0:00:00.400473\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:18 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.708 mean_absolute_error: 0.660 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:18 INFO 140033525749568] Epoch: 1, batches: 200, num_examples: 12800, 15983.0 samples/sec, epoch time so far: 0:00:00.800853\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:18 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.702 mean_absolute_error: 0.659 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:18 INFO 140033525749568] Epoch: 1, batches: 300, num_examples: 19200, 15858.7 samples/sec, epoch time so far: 0:00:01.210691\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:18 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.714 mean_absolute_error: 0.664 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:19 INFO 140033525749568] Epoch: 1, batches: 400, num_examples: 25600, 15868.9 samples/sec, epoch time so far: 0:00:01.613222\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:19 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.703 mean_absolute_error: 0.658 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:19 INFO 140033525749568] Epoch: 1, batches: 500, num_examples: 32000, 15909.3 samples/sec, epoch time so far: 0:00:02.011403\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:19 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.695 mean_absolute_error: 0.655 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:20 INFO 140033525749568] Epoch: 1, batches: 600, num_examples: 38400, 15922.5 samples/sec, epoch time so far: 0:00:02.411684\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:20 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.689 mean_absolute_error: 0.652 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:20 INFO 140033525749568] Epoch: 1, batches: 700, num_examples: 44800, 15936.0 samples/sec, epoch time so far: 0:00:02.811245\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:20 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.683 mean_absolute_error: 0.649 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:20 INFO 140033525749568] Epoch: 1, batches: 800, num_examples: 51200, 15912.5 samples/sec, epoch time so far: 0:00:03.217592\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:20 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.676 mean_absolute_error: 0.646 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:21 INFO 140033525749568] Epoch: 1, batches: 900, num_examples: 57600, 15925.2 samples/sec, epoch time so far: 0:00:03.616901\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:21 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.673 mean_absolute_error: 0.645 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:21 INFO 140033525749568] Epoch: 1, batches: 1000, num_examples: 64000, 15933.9 samples/sec, epoch time so far: 0:00:04.016594\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:21 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.671 mean_absolute_error: 0.643 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:22 INFO 140033525749568] Epoch: 1, batches: 1100, num_examples: 70400, 15939.0 samples/sec, epoch time so far: 0:00:04.416828\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:22 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.666 mean_absolute_error: 0.641 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:22 INFO 140033525749568] Epoch: 1, batches: 1200, num_examples: 76800, 15945.0 samples/sec, epoch time so far: 0:00:04.816571\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:22 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.663 mean_absolute_error: 0.639 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:22 INFO 140033525749568] Epoch: 1, batches: 1300, num_examples: 83200, 15940.9 samples/sec, epoch time so far: 0:00:05.219279\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:22 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.660 mean_absolute_error: 0.638 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] Epoch: 1, batches: 1400, num_examples: 89600, 15945.3 samples/sec, epoch time so far: 0:00:05.619199\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.657 mean_absolute_error: 0.637 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] Completed Epoch: 1, time taken: 0:00:05.683381\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] Epoch 1 Training metrics:   mean_squared_error: 0.657 mean_absolute_error: 0.636 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] #quality_metric: host=algo-1, epoch=1, train mean_squared_error <loss>=0.657121398313\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] Epoch 1 Validation metrics: mean_squared_error: 0.971 mean_absolute_error: 0.776 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] #quality_metric: host=algo-1, epoch=1, validation mean_squared_error <loss>=0.971182005228\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.03314018249511719, \"sum\": 0.03314018249511719, \"min\": 0.03314018249511719}, \"update.time\": {\"count\": 1, \"max\": 5872.673988342285, \"sum\": 5872.673988342285, \"min\": 5872.673988342285}}, \"EndTime\": 1539788243.474372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788237.584974}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2832, \"sum\": 2832.0, \"min\": 2832}, \"Total Records Seen\": {\"count\": 1, \"max\": 181248, \"sum\": 181248.0, \"min\": 181248}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1539788243.474632, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 1}, \"StartTime\": 1539788237.601676}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15430.3837786 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] Epoch: 2, batches: 100, num_examples: 6400, 15696.0 samples/sec, epoch time so far: 0:00:00.407748\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:23 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.278 mean_absolute_error: 0.402 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:24 INFO 140033525749568] Epoch: 2, batches: 200, num_examples: 12800, 15871.5 samples/sec, epoch time so far: 0:00:00.806478\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:24 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.273 mean_absolute_error: 0.398 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:24 INFO 140033525749568] Epoch: 2, batches: 300, num_examples: 19200, 15919.9 samples/sec, epoch time so far: 0:00:01.206040\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:24 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.267 mean_absolute_error: 0.394 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:25 INFO 140033525749568] Epoch: 2, batches: 400, num_examples: 25600, 15898.1 samples/sec, epoch time so far: 0:00:01.610251\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:25 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.264 mean_absolute_error: 0.393 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:25 INFO 140033525749568] Epoch: 2, batches: 500, num_examples: 32000, 15890.9 samples/sec, epoch time so far: 0:00:02.013727\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:25 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.266 mean_absolute_error: 0.395 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:25 INFO 140033525749568] Epoch: 2, batches: 600, num_examples: 38400, 15907.3 samples/sec, epoch time so far: 0:00:02.413988\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:25 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.267 mean_absolute_error: 0.396 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:26 INFO 140033525749568] Epoch: 2, batches: 700, num_examples: 44800, 15856.7 samples/sec, epoch time so far: 0:00:02.825297\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:26 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.267 mean_absolute_error: 0.395 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/17/2018 14:57:26 INFO 140033525749568] Epoch: 2, batches: 800, num_examples: 51200, 15866.6 samples/sec, epoch time so far: 0:00:03.226903\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:26 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.268 mean_absolute_error: 0.397 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:27 INFO 140033525749568] Epoch: 2, batches: 900, num_examples: 57600, 15863.1 samples/sec, epoch time so far: 0:00:03.631070\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:27 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.269 mean_absolute_error: 0.397 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:27 INFO 140033525749568] Epoch: 2, batches: 1000, num_examples: 64000, 15873.8 samples/sec, epoch time so far: 0:00:04.031794\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:27 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.270 mean_absolute_error: 0.398 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:27 INFO 140033525749568] Epoch: 2, batches: 1100, num_examples: 70400, 15890.9 samples/sec, epoch time so far: 0:00:04.430206\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:27 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.270 mean_absolute_error: 0.399 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:28 INFO 140033525749568] Epoch: 2, batches: 1200, num_examples: 76800, 15904.6 samples/sec, epoch time so far: 0:00:04.828786\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:28 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.272 mean_absolute_error: 0.400 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:28 INFO 140033525749568] Epoch: 2, batches: 1300, num_examples: 83200, 15897.7 samples/sec, epoch time so far: 0:00:05.233459\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:28 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.274 mean_absolute_error: 0.401 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] Epoch: 2, batches: 1400, num_examples: 89600, 15860.4 samples/sec, epoch time so far: 0:00:05.649283\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.275 mean_absolute_error: 0.402 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] Completed Epoch: 2, time taken: 0:00:05.713532\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] Epoch 2 Training metrics:   mean_squared_error: 0.275 mean_absolute_error: 0.403 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] #quality_metric: host=algo-1, epoch=2, train mean_squared_error <loss>=0.275329749242\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] Epoch 2 Validation metrics: mean_squared_error: 0.933 mean_absolute_error: 0.766 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] #quality_metric: host=algo-1, epoch=2, validation mean_squared_error <loss>=0.933360045826\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 2.177000045776367, \"sum\": 2.177000045776367, \"min\": 2.177000045776367}, \"update.time\": {\"count\": 1, \"max\": 5902.961015701294, \"sum\": 5902.961015701294, \"min\": 5902.961015701294}}, \"EndTime\": 1539788249.382691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788243.474451}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 4248, \"sum\": 4248.0, \"min\": 4248}, \"Total Records Seen\": {\"count\": 1, \"max\": 271872, \"sum\": 271872.0, \"min\": 271872}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1539788249.382995, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 2}, \"StartTime\": 1539788243.479705}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15351.0756 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] Epoch: 3, batches: 100, num_examples: 6400, 15984.3 samples/sec, epoch time so far: 0:00:00.400392\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:29 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.170 mean_absolute_error: 0.300 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:30 INFO 140033525749568] Epoch: 3, batches: 200, num_examples: 12800, 15993.0 samples/sec, epoch time so far: 0:00:00.800350\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:30 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.161 mean_absolute_error: 0.293 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:30 INFO 140033525749568] Epoch: 3, batches: 300, num_examples: 19200, 15956.3 samples/sec, epoch time so far: 0:00:01.203285\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:30 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.291 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:31 INFO 140033525749568] Epoch: 3, batches: 400, num_examples: 25600, 15955.6 samples/sec, epoch time so far: 0:00:01.604454\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:31 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.292 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:31 INFO 140033525749568] Epoch: 3, batches: 500, num_examples: 32000, 15957.8 samples/sec, epoch time so far: 0:00:02.005288\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:31 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.158 mean_absolute_error: 0.292 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:31 INFO 140033525749568] Epoch: 3, batches: 600, num_examples: 38400, 15964.5 samples/sec, epoch time so far: 0:00:02.405340\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:31 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.158 mean_absolute_error: 0.292 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:32 INFO 140033525749568] Epoch: 3, batches: 700, num_examples: 44800, 15969.0 samples/sec, epoch time so far: 0:00:02.805442\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:32 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.156 mean_absolute_error: 0.292 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:32 INFO 140033525749568] Epoch: 3, batches: 800, num_examples: 51200, 15955.8 samples/sec, epoch time so far: 0:00:03.208856\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:32 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.157 mean_absolute_error: 0.293 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:33 INFO 140033525749568] Epoch: 3, batches: 900, num_examples: 57600, 15957.0 samples/sec, epoch time so far: 0:00:03.609711\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:33 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.158 mean_absolute_error: 0.294 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:33 INFO 140033525749568] Epoch: 3, batches: 1000, num_examples: 64000, 15952.9 samples/sec, epoch time so far: 0:00:04.011802\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:33 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.158 mean_absolute_error: 0.295 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:33 INFO 140033525749568] Epoch: 3, batches: 1100, num_examples: 70400, 15924.1 samples/sec, epoch time so far: 0:00:04.420978\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:33 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.296 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:34 INFO 140033525749568] Epoch: 3, batches: 1200, num_examples: 76800, 15929.2 samples/sec, epoch time so far: 0:00:04.821349\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:34 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.296 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:34 INFO 140033525749568] Epoch: 3, batches: 1300, num_examples: 83200, 15933.6 samples/sec, epoch time so far: 0:00:05.221658\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:34 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.160 mean_absolute_error: 0.297 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] Epoch: 3, batches: 1400, num_examples: 89600, 15941.6 samples/sec, epoch time so far: 0:00:05.620502\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.160 mean_absolute_error: 0.298 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] Completed Epoch: 3, time taken: 0:00:05.684757\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] Epoch 3 Training metrics:   mean_squared_error: 0.161 mean_absolute_error: 0.298 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] #quality_metric: host=algo-1, epoch=3, train mean_squared_error <loss>=0.1605647752\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] Epoch 3 Validation metrics: mean_squared_error: 0.941 mean_absolute_error: 0.772 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] #quality_metric: host=algo-1, epoch=3, validation mean_squared_error <loss>=0.941012832361\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] patience losses: [0.95102707034832723, 0.97118200522822307, 0.93336004582611287]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] min patience losses: 0.933360045826\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] current loss: 0.941012832361\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] absolute loss difference: 0.00765278653519\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.5447864532470703, \"sum\": 0.5447864532470703, \"min\": 0.5447864532470703}, \"update.time\": {\"count\": 1, \"max\": 5879.083871841431, \"sum\": 5879.083871841431, \"min\": 5879.083871841431}}, \"EndTime\": 1539788255.284052, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788249.382793}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 5664, \"sum\": 5664.0, \"min\": 5664}, \"Total Records Seen\": {\"count\": 1, \"max\": 362496, \"sum\": 362496.0, \"min\": 362496}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1539788255.284369, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 3}, \"StartTime\": 1539788249.404942}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15413.3695471 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] Epoch: 4, batches: 100, num_examples: 6400, 15943.3 samples/sec, epoch time so far: 0:00:00.401422\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:35 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.121 mean_absolute_error: 0.259 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:36 INFO 140033525749568] Epoch: 4, batches: 200, num_examples: 12800, 15982.3 samples/sec, epoch time so far: 0:00:00.800885\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:36 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.116 mean_absolute_error: 0.254 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/17/2018 14:57:36 INFO 140033525749568] Epoch: 4, batches: 300, num_examples: 19200, 15986.8 samples/sec, epoch time so far: 0:00:01.200993\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:36 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.115 mean_absolute_error: 0.254 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:36 INFO 140033525749568] Epoch: 4, batches: 400, num_examples: 25600, 15987.1 samples/sec, epoch time so far: 0:00:01.601289\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:36 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.113 mean_absolute_error: 0.252 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:37 INFO 140033525749568] Epoch: 4, batches: 500, num_examples: 32000, 15993.9 samples/sec, epoch time so far: 0:00:02.000769\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:37 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.114 mean_absolute_error: 0.253 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:37 INFO 140033525749568] Epoch: 4, batches: 600, num_examples: 38400, 15973.7 samples/sec, epoch time so far: 0:00:02.403946\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:37 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.114 mean_absolute_error: 0.253 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:38 INFO 140033525749568] Epoch: 4, batches: 700, num_examples: 44800, 15978.2 samples/sec, epoch time so far: 0:00:02.803823\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:38 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.113 mean_absolute_error: 0.253 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:38 INFO 140033525749568] Epoch: 4, batches: 800, num_examples: 51200, 15977.8 samples/sec, epoch time so far: 0:00:03.204447\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:38 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.113 mean_absolute_error: 0.252 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:38 INFO 140033525749568] Epoch: 4, batches: 900, num_examples: 57600, 15965.7 samples/sec, epoch time so far: 0:00:03.607731\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:38 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.112 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:39 INFO 140033525749568] Epoch: 4, batches: 1000, num_examples: 64000, 15969.0 samples/sec, epoch time so far: 0:00:04.007765\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:39 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.112 mean_absolute_error: 0.252 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:39 INFO 140033525749568] Epoch: 4, batches: 1100, num_examples: 70400, 15964.0 samples/sec, epoch time so far: 0:00:04.409926\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:39 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.112 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:40 INFO 140033525749568] Epoch: 4, batches: 1200, num_examples: 76800, 15970.1 samples/sec, epoch time so far: 0:00:04.808973\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:40 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.112 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:40 INFO 140033525749568] Epoch: 4, batches: 1300, num_examples: 83200, 15970.6 samples/sec, epoch time so far: 0:00:05.209577\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:40 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.112 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:40 INFO 140033525749568] Epoch: 4, batches: 1400, num_examples: 89600, 15974.7 samples/sec, epoch time so far: 0:00:05.608870\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:40 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.112 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:40 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:40 INFO 140033525749568] Completed Epoch: 4, time taken: 0:00:05.672791\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:40 INFO 140033525749568] Epoch 4 Training metrics:   mean_squared_error: 0.112 mean_absolute_error: 0.252 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:40 INFO 140033525749568] #quality_metric: host=algo-1, epoch=4, train mean_squared_error <loss>=0.111566696284\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] Epoch 4 Validation metrics: mean_squared_error: 0.933 mean_absolute_error: 0.765 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] #quality_metric: host=algo-1, epoch=4, validation mean_squared_error <loss>=0.933420505878\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] patience losses: [0.97118200522822307, 0.93336004582611287, 0.94101283236129862]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] min patience losses: 0.933360045826\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] current loss: 0.933420505878\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] absolute loss difference: 6.04600519748e-05\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.47397613525390625, \"sum\": 0.47397613525390625, \"min\": 0.47397613525390625}, \"update.time\": {\"count\": 1, \"max\": 5861.531972885132, \"sum\": 5861.531972885132, \"min\": 5861.531972885132}}, \"EndTime\": 1539788261.151078, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788255.284188}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7080, \"sum\": 7080.0, \"min\": 7080}, \"Total Records Seen\": {\"count\": 1, \"max\": 453120, \"sum\": 453120.0, \"min\": 453120}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1539788261.151305, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 4}, \"StartTime\": 1539788255.289526}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15459.8732158 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] Epoch: 5, batches: 100, num_examples: 6400, 15803.8 samples/sec, epoch time so far: 0:00:00.404967\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.096 mean_absolute_error: 0.238 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] Epoch: 5, batches: 200, num_examples: 12800, 15840.5 samples/sec, epoch time so far: 0:00:00.808056\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:41 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.093 mean_absolute_error: 0.234 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:42 INFO 140033525749568] Epoch: 5, batches: 300, num_examples: 19200, 15899.5 samples/sec, epoch time so far: 0:00:01.207588\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:42 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.090 mean_absolute_error: 0.231 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:42 INFO 140033525749568] Epoch: 5, batches: 400, num_examples: 25600, 15901.1 samples/sec, epoch time so far: 0:00:01.609948\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:42 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:43 INFO 140033525749568] Epoch: 5, batches: 500, num_examples: 32000, 15921.7 samples/sec, epoch time so far: 0:00:02.009831\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:43 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:43 INFO 140033525749568] Epoch: 5, batches: 600, num_examples: 38400, 15932.0 samples/sec, epoch time so far: 0:00:02.410248\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:43 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:43 INFO 140033525749568] Epoch: 5, batches: 700, num_examples: 44800, 15843.0 samples/sec, epoch time so far: 0:00:02.827750\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:43 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:44 INFO 140033525749568] Epoch: 5, batches: 800, num_examples: 51200, 15855.0 samples/sec, epoch time so far: 0:00:03.229274\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:44 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:44 INFO 140033525749568] Epoch: 5, batches: 900, num_examples: 57600, 15866.6 samples/sec, epoch time so far: 0:00:03.630262\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:44 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:45 INFO 140033525749568] Epoch: 5, batches: 1000, num_examples: 64000, 15881.6 samples/sec, epoch time so far: 0:00:04.029820\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:45 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:45 INFO 140033525749568] Epoch: 5, batches: 1100, num_examples: 70400, 15887.1 samples/sec, epoch time so far: 0:00:04.431281\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:45 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:45 INFO 140033525749568] Epoch: 5, batches: 1200, num_examples: 76800, 15889.9 samples/sec, epoch time so far: 0:00:04.833256\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:45 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:46 INFO 140033525749568] Epoch: 5, batches: 1300, num_examples: 83200, 15896.3 samples/sec, epoch time so far: 0:00:05.233918\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:46 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.230 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/17/2018 14:57:46 INFO 140033525749568] Epoch: 5, batches: 1400, num_examples: 89600, 15898.2 samples/sec, epoch time so far: 0:00:05.635863\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:46 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:46 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:46 INFO 140033525749568] Completed Epoch: 5, time taken: 0:00:05.699553\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:46 INFO 140033525749568] Epoch 5 Training metrics:   mean_squared_error: 0.089 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:46 INFO 140033525749568] #quality_metric: host=algo-1, epoch=5, train mean_squared_error <loss>=0.0887031297852\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] Epoch 5 Validation metrics: mean_squared_error: 0.934 mean_absolute_error: 0.764 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] #quality_metric: host=algo-1, epoch=5, validation mean_squared_error <loss>=0.934171690329\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] patience losses: [0.93336004582611287, 0.94101283236129862, 0.93342050587808767]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] min patience losses: 0.933360045826\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] current loss: 0.934171690329\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] absolute loss difference: 0.000811644502588\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.45609474182128906, \"sum\": 0.45609474182128906, \"min\": 0.45609474182128906}, \"update.time\": {\"count\": 1, \"max\": 5887.768983840942, \"sum\": 5887.768983840942, \"min\": 5887.768983840942}}, \"EndTime\": 1539788267.044156, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788261.151152}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 8496, \"sum\": 8496.0, \"min\": 8496}, \"Total Records Seen\": {\"count\": 1, \"max\": 543744, \"sum\": 543744.0, \"min\": 543744}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1539788267.044429, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 5}, \"StartTime\": 1539788261.156368}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15390.8101131 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] Epoch: 6, batches: 100, num_examples: 6400, 16105.2 samples/sec, epoch time so far: 0:00:00.397388\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.231 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] Epoch: 6, batches: 200, num_examples: 12800, 16007.0 samples/sec, epoch time so far: 0:00:00.799650\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:47 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:48 INFO 140033525749568] Epoch: 6, batches: 300, num_examples: 19200, 15982.4 samples/sec, epoch time so far: 0:00:01.201321\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:48 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:48 INFO 140033525749568] Epoch: 6, batches: 400, num_examples: 25600, 15970.4 samples/sec, epoch time so far: 0:00:01.602970\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:48 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:49 INFO 140033525749568] Epoch: 6, batches: 500, num_examples: 32000, 15915.8 samples/sec, epoch time so far: 0:00:02.010581\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:49 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:49 INFO 140033525749568] Epoch: 6, batches: 600, num_examples: 38400, 15937.9 samples/sec, epoch time so far: 0:00:02.409351\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:49 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:49 INFO 140033525749568] Epoch: 6, batches: 700, num_examples: 44800, 15950.0 samples/sec, epoch time so far: 0:00:02.808784\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:49 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.223 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:50 INFO 140033525749568] Epoch: 6, batches: 800, num_examples: 51200, 15942.6 samples/sec, epoch time so far: 0:00:03.211517\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:50 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.223 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:50 INFO 140033525749568] Epoch: 6, batches: 900, num_examples: 57600, 15946.6 samples/sec, epoch time so far: 0:00:03.612059\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:50 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.223 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:51 INFO 140033525749568] Epoch: 6, batches: 1000, num_examples: 64000, 15952.9 samples/sec, epoch time so far: 0:00:04.011815\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:51 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.223 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:51 INFO 140033525749568] Epoch: 6, batches: 1100, num_examples: 70400, 15959.8 samples/sec, epoch time so far: 0:00:04.411090\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:51 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:51 INFO 140033525749568] Epoch: 6, batches: 1200, num_examples: 76800, 15960.3 samples/sec, epoch time so far: 0:00:04.811928\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:51 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] Epoch: 6, batches: 1300, num_examples: 83200, 15951.4 samples/sec, epoch time so far: 0:00:05.215854\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.223 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] Epoch: 6, batches: 1400, num_examples: 89600, 15954.8 samples/sec, epoch time so far: 0:00:05.615858\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.223 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] Completed Epoch: 6, time taken: 0:00:05.680525\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] Epoch 6 Training metrics:   mean_squared_error: 0.083 mean_absolute_error: 0.223 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] #quality_metric: host=algo-1, epoch=6, train mean_squared_error <loss>=0.0828120581843\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] Epoch 6 Validation metrics: mean_squared_error: 0.923 mean_absolute_error: 0.760 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] #quality_metric: host=algo-1, epoch=6, validation mean_squared_error <loss>=0.92337119982\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] patience losses: [0.94101283236129862, 0.93342050587808767, 0.93417169032870118]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] min patience losses: 0.933420505878\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] current loss: 0.92337119982\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] absolute loss difference: 0.0100493060576\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 2.2809505462646484, \"sum\": 2.2809505462646484, \"min\": 2.2809505462646484}, \"update.time\": {\"count\": 1, \"max\": 5871.364116668701, \"sum\": 5871.364116668701, \"min\": 5871.364116668701}}, \"EndTime\": 1539788272.92089, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788267.044242}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 9912, \"sum\": 9912.0, \"min\": 9912}, \"Total Records Seen\": {\"count\": 1, \"max\": 634368, \"sum\": 634368.0, \"min\": 634368}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1539788272.921133, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 6}, \"StartTime\": 1539788267.049465}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:52 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15433.7551624 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:53 INFO 140033525749568] Epoch: 7, batches: 100, num_examples: 6400, 16049.1 samples/sec, epoch time so far: 0:00:00.398776\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:53 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:53 INFO 140033525749568] Epoch: 7, batches: 200, num_examples: 12800, 16001.2 samples/sec, epoch time so far: 0:00:00.799942\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:53 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:54 INFO 140033525749568] Epoch: 7, batches: 300, num_examples: 19200, 15832.6 samples/sec, epoch time so far: 0:00:01.212687\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:54 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.079 mean_absolute_error: 0.218 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:54 INFO 140033525749568] Epoch: 7, batches: 400, num_examples: 25600, 15835.8 samples/sec, epoch time so far: 0:00:01.616594\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:54 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.216 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:54 INFO 140033525749568] Epoch: 7, batches: 500, num_examples: 32000, 15863.4 samples/sec, epoch time so far: 0:00:02.017221\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:54 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.216 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:55 INFO 140033525749568] Epoch: 7, batches: 600, num_examples: 38400, 15894.9 samples/sec, epoch time so far: 0:00:02.415874\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:55 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.215 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:55 INFO 140033525749568] Epoch: 7, batches: 700, num_examples: 44800, 15895.5 samples/sec, epoch time so far: 0:00:02.818406\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:55 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.215 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:56 INFO 140033525749568] Epoch: 7, batches: 800, num_examples: 51200, 15906.2 samples/sec, epoch time so far: 0:00:03.218875\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:56 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.215 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/17/2018 14:57:56 INFO 140033525749568] Epoch: 7, batches: 900, num_examples: 57600, 15889.8 samples/sec, epoch time so far: 0:00:03.624960\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:56 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:56 INFO 140033525749568] Epoch: 7, batches: 1000, num_examples: 64000, 15901.5 samples/sec, epoch time so far: 0:00:04.024782\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:56 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:57 INFO 140033525749568] Epoch: 7, batches: 1100, num_examples: 70400, 15907.5 samples/sec, epoch time so far: 0:00:04.425592\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:57 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:57 INFO 140033525749568] Epoch: 7, batches: 1200, num_examples: 76800, 15914.8 samples/sec, epoch time so far: 0:00:04.825692\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:57 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] Epoch: 7, batches: 1300, num_examples: 83200, 15924.5 samples/sec, epoch time so far: 0:00:05.224638\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] Epoch: 7, batches: 1400, num_examples: 89600, 15908.2 samples/sec, epoch time so far: 0:00:05.632324\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] Completed Epoch: 7, time taken: 0:00:05.696829\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] Epoch 7 Training metrics:   mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] #quality_metric: host=algo-1, epoch=7, train mean_squared_error <loss>=0.0766178802719\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] Epoch 7 Validation metrics: mean_squared_error: 0.929 mean_absolute_error: 0.762 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] #quality_metric: host=algo-1, epoch=7, validation mean_squared_error <loss>=0.929394307169\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] patience losses: [0.93342050587808767, 0.93417169032870118, 0.92337119982049276]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] min patience losses: 0.92337119982\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] current loss: 0.929394307169\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] absolute loss difference: 0.00602310734826\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.4639625549316406, \"sum\": 0.4639625549316406, \"min\": 0.4639625549316406}, \"update.time\": {\"count\": 1, \"max\": 5889.669895172119, \"sum\": 5889.669895172119, \"min\": 5889.669895172119}}, \"EndTime\": 1539788278.827151, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788272.920964}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 11328, \"sum\": 11328.0, \"min\": 11328}, \"Total Records Seen\": {\"count\": 1, \"max\": 724992, \"sum\": 724992.0, \"min\": 724992}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1539788278.827407, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 7}, \"StartTime\": 1539788272.937455}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:58 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15385.709755 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:59 INFO 140033525749568] Epoch: 8, batches: 100, num_examples: 6400, 15466.1 samples/sec, epoch time so far: 0:00:00.413808\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:59 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.071 mean_absolute_error: 0.204 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:59 INFO 140033525749568] Epoch: 8, batches: 200, num_examples: 12800, 15712.4 samples/sec, epoch time so far: 0:00:00.814643\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:57:59 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.069 mean_absolute_error: 0.201 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:00 INFO 140033525749568] Epoch: 8, batches: 300, num_examples: 19200, 15804.8 samples/sec, epoch time so far: 0:00:01.214820\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:00 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.068 mean_absolute_error: 0.200 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:00 INFO 140033525749568] Epoch: 8, batches: 400, num_examples: 25600, 15825.2 samples/sec, epoch time so far: 0:00:01.617669\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:00 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.068 mean_absolute_error: 0.200 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:00 INFO 140033525749568] Epoch: 8, batches: 500, num_examples: 32000, 15854.0 samples/sec, epoch time so far: 0:00:02.018422\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:00 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.068 mean_absolute_error: 0.199 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:01 INFO 140033525749568] Epoch: 8, batches: 600, num_examples: 38400, 15864.5 samples/sec, epoch time so far: 0:00:02.420499\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:01 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.068 mean_absolute_error: 0.199 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:01 INFO 140033525749568] Epoch: 8, batches: 700, num_examples: 44800, 15864.6 samples/sec, epoch time so far: 0:00:02.823894\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:01 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.068 mean_absolute_error: 0.199 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:02 INFO 140033525749568] Epoch: 8, batches: 800, num_examples: 51200, 15875.8 samples/sec, epoch time so far: 0:00:03.225040\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:02 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.198 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:02 INFO 140033525749568] Epoch: 8, batches: 900, num_examples: 57600, 15880.9 samples/sec, epoch time so far: 0:00:03.626998\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:02 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.197 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:02 INFO 140033525749568] Epoch: 8, batches: 1000, num_examples: 64000, 15883.8 samples/sec, epoch time so far: 0:00:04.029262\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:02 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.066 mean_absolute_error: 0.197 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:03 INFO 140033525749568] Epoch: 8, batches: 1100, num_examples: 70400, 15895.3 samples/sec, epoch time so far: 0:00:04.428972\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:03 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.066 mean_absolute_error: 0.196 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:03 INFO 140033525749568] Epoch: 8, batches: 1200, num_examples: 76800, 15901.6 samples/sec, epoch time so far: 0:00:04.829698\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:03 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.066 mean_absolute_error: 0.196 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] Epoch: 8, batches: 1300, num_examples: 83200, 15895.3 samples/sec, epoch time so far: 0:00:05.234256\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.196 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] Epoch: 8, batches: 1400, num_examples: 89600, 15874.0 samples/sec, epoch time so far: 0:00:05.644438\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.066 mean_absolute_error: 0.196 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] Completed Epoch: 8, time taken: 0:00:05.708503\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] Epoch 8 Training metrics:   mean_squared_error: 0.066 mean_absolute_error: 0.196 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] #quality_metric: host=algo-1, epoch=8, train mean_squared_error <loss>=0.0655773614368\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] Epoch 8 Validation metrics: mean_squared_error: 0.911 mean_absolute_error: 0.753 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] #quality_metric: host=algo-1, epoch=8, validation mean_squared_error <loss>=0.911185323789\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] patience losses: [0.93417169032870118, 0.92337119982049276, 0.92939430716875437]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] min patience losses: 0.92337119982\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] current loss: 0.911185323789\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] absolute loss difference: 0.0121858760312\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 2.468109130859375, \"sum\": 2.468109130859375, \"min\": 2.468109130859375}, \"update.time\": {\"count\": 1, \"max\": 5915.51399230957, \"sum\": 5915.51399230957, \"min\": 5915.51399230957}}, \"EndTime\": 1539788284.748131, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788278.827241}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 12744, \"sum\": 12744.0, \"min\": 12744}, \"Total Records Seen\": {\"count\": 1, \"max\": 815616, \"sum\": 815616.0, \"min\": 815616}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1539788284.748399, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 8}, \"StartTime\": 1539788278.832594}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:04 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15318.6167459 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:05 INFO 140033525749568] Epoch: 9, batches: 100, num_examples: 6400, 15982.6 samples/sec, epoch time so far: 0:00:00.400435\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:05 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.058 mean_absolute_error: 0.184 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:05 INFO 140033525749568] Epoch: 9, batches: 200, num_examples: 12800, 15989.6 samples/sec, epoch time so far: 0:00:00.800523\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:05 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.058 mean_absolute_error: 0.184 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:05 INFO 140033525749568] Epoch: 9, batches: 300, num_examples: 19200, 15984.8 samples/sec, epoch time so far: 0:00:01.201139\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:05 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.182 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:06 INFO 140033525749568] Epoch: 9, batches: 400, num_examples: 25600, 15991.7 samples/sec, epoch time so far: 0:00:01.600831\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:06 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.181 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:06 INFO 140033525749568] Epoch: 9, batches: 500, num_examples: 32000, 15980.2 samples/sec, epoch time so far: 0:00:02.002472\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:06 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.182 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:07 INFO 140033525749568] Epoch: 9, batches: 600, num_examples: 38400, 15974.1 samples/sec, epoch time so far: 0:00:02.403898\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:07 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.182 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:07 INFO 140033525749568] Epoch: 9, batches: 700, num_examples: 44800, 15976.7 samples/sec, epoch time so far: 0:00:02.804089\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:07 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:07 INFO 140033525749568] Epoch: 9, batches: 800, num_examples: 51200, 15980.5 samples/sec, epoch time so far: 0:00:03.203912\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:07 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:08 INFO 140033525749568] Epoch: 9, batches: 900, num_examples: 57600, 15977.7 samples/sec, epoch time so far: 0:00:03.605019\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:08 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.182 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:08 INFO 140033525749568] Epoch: 9, batches: 1000, num_examples: 64000, 15965.1 samples/sec, epoch time so far: 0:00:04.008756\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:08 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:09 INFO 140033525749568] Epoch: 9, batches: 1100, num_examples: 70400, 15895.8 samples/sec, epoch time so far: 0:00:04.428855\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:09 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.182 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:09 INFO 140033525749568] Epoch: 9, batches: 1200, num_examples: 76800, 15894.7 samples/sec, epoch time so far: 0:00:04.831785\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:09 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] Epoch: 9, batches: 1300, num_examples: 83200, 15899.9 samples/sec, epoch time so far: 0:00:05.232749\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] Epoch: 9, batches: 1400, num_examples: 89600, 15909.1 samples/sec, epoch time so far: 0:00:05.632002\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] Completed Epoch: 9, time taken: 0:00:05.696632\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] Epoch 9 Training metrics:   mean_squared_error: 0.057 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] #quality_metric: host=algo-1, epoch=9, train mean_squared_error <loss>=0.0573778830213\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] Epoch 9 Validation metrics: mean_squared_error: 0.914 mean_absolute_error: 0.753 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] #quality_metric: host=algo-1, epoch=9, validation mean_squared_error <loss>=0.91358408936\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] patience losses: [0.92337119982049276, 0.92939430716875437, 0.91118532378931305]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] min patience losses: 0.911185323789\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] current loss: 0.91358408936\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] absolute loss difference: 0.00239876557041\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.4680156707763672, \"sum\": 0.4680156707763672, \"min\": 0.4680156707763672}, \"update.time\": {\"count\": 1, \"max\": 5885.663032531738, \"sum\": 5885.663032531738, \"min\": 5885.663032531738}}, \"EndTime\": 1539788290.655753, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788284.74822}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 14160, \"sum\": 14160.0, \"min\": 14160}, \"Total Records Seen\": {\"count\": 1, \"max\": 906240, \"sum\": 906240.0, \"min\": 906240}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1539788290.655972, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 9}, \"StartTime\": 1539788284.770064}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:10 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15396.3903009 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:11 INFO 140033525749568] Epoch: 10, batches: 100, num_examples: 6400, 15794.6 samples/sec, epoch time so far: 0:00:00.405202\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:11 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.182 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:11 INFO 140033525749568] Epoch: 10, batches: 200, num_examples: 12800, 15892.8 samples/sec, epoch time so far: 0:00:00.805394\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:11 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.055 mean_absolute_error: 0.177 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/17/2018 14:58:11 INFO 140033525749568] Epoch: 10, batches: 300, num_examples: 19200, 15923.3 samples/sec, epoch time so far: 0:00:01.205781\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:11 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.054 mean_absolute_error: 0.176 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:12 INFO 140033525749568] Epoch: 10, batches: 400, num_examples: 25600, 15947.6 samples/sec, epoch time so far: 0:00:01.605262\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:12 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.174 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:12 INFO 140033525749568] Epoch: 10, batches: 500, num_examples: 32000, 15953.3 samples/sec, epoch time so far: 0:00:02.005858\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:12 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.174 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:13 INFO 140033525749568] Epoch: 10, batches: 600, num_examples: 38400, 15931.7 samples/sec, epoch time so far: 0:00:02.410293\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:13 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.173 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:13 INFO 140033525749568] Epoch: 10, batches: 700, num_examples: 44800, 15948.1 samples/sec, epoch time so far: 0:00:02.809108\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:13 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.174 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:13 INFO 140033525749568] Epoch: 10, batches: 800, num_examples: 51200, 15945.6 samples/sec, epoch time so far: 0:00:03.210924\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:13 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.174 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:14 INFO 140033525749568] Epoch: 10, batches: 900, num_examples: 57600, 15913.4 samples/sec, epoch time so far: 0:00:03.619584\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:14 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.173 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:14 INFO 140033525749568] Epoch: 10, batches: 1000, num_examples: 64000, 15919.1 samples/sec, epoch time so far: 0:00:04.020339\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:14 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.173 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:15 INFO 140033525749568] Epoch: 10, batches: 1100, num_examples: 70400, 15896.4 samples/sec, epoch time so far: 0:00:04.428683\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:15 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.173 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:15 INFO 140033525749568] Epoch: 10, batches: 1200, num_examples: 76800, 15900.9 samples/sec, epoch time so far: 0:00:04.829909\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:15 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.173 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:15 INFO 140033525749568] Epoch: 10, batches: 1300, num_examples: 83200, 15909.2 samples/sec, epoch time so far: 0:00:05.229667\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:15 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.173 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] Epoch: 10, batches: 1400, num_examples: 89600, 15917.9 samples/sec, epoch time so far: 0:00:05.628887\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.174 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] Completed Epoch: 10, time taken: 0:00:05.692683\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] Epoch 10 Training metrics:   mean_squared_error: 0.053 mean_absolute_error: 0.174 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] #quality_metric: host=algo-1, epoch=10, train mean_squared_error <loss>=0.052722025781\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] Epoch 10 Validation metrics: mean_squared_error: 0.914 mean_absolute_error: 0.756 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] #quality_metric: host=algo-1, epoch=10, validation mean_squared_error <loss>=0.914233740117\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] patience losses: [0.92939430716875437, 0.91118532378931305, 0.91358408935972157]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] min patience losses: 0.911185323789\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] current loss: 0.914233740117\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] absolute loss difference: 0.00304841632779\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.40602684020996094, \"sum\": 0.40602684020996094, \"min\": 0.40602684020996094}, \"update.time\": {\"count\": 1, \"max\": 5881.376028060913, \"sum\": 5881.376028060913, \"min\": 5881.376028060913}}, \"EndTime\": 1539788296.542452, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788290.655826}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 15576, \"sum\": 15576.0, \"min\": 15576}, \"Total Records Seen\": {\"count\": 1, \"max\": 996864, \"sum\": 996864.0, \"min\": 996864}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1539788296.542683, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 10}, \"StartTime\": 1539788290.661058}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15407.6309004 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] Epoch: 11, batches: 100, num_examples: 6400, 15785.4 samples/sec, epoch time so far: 0:00:00.405437\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:16 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.171 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:17 INFO 140033525749568] Epoch: 11, batches: 200, num_examples: 12800, 15804.0 samples/sec, epoch time so far: 0:00:00.809922\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:17 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.050 mean_absolute_error: 0.167 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:17 INFO 140033525749568] Epoch: 11, batches: 300, num_examples: 19200, 15872.8 samples/sec, epoch time so far: 0:00:01.209619\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:17 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.049 mean_absolute_error: 0.165 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:18 INFO 140033525749568] Epoch: 11, batches: 400, num_examples: 25600, 15907.3 samples/sec, epoch time so far: 0:00:01.609328\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:18 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.048 mean_absolute_error: 0.164 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:18 INFO 140033525749568] Epoch: 11, batches: 500, num_examples: 32000, 15917.5 samples/sec, epoch time so far: 0:00:02.010372\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:18 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.048 mean_absolute_error: 0.163 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:18 INFO 140033525749568] Epoch: 11, batches: 600, num_examples: 38400, 15930.1 samples/sec, epoch time so far: 0:00:02.410533\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:18 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.048 mean_absolute_error: 0.163 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:19 INFO 140033525749568] Epoch: 11, batches: 700, num_examples: 44800, 15861.5 samples/sec, epoch time so far: 0:00:02.824452\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:19 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.047 mean_absolute_error: 0.162 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:19 INFO 140033525749568] Epoch: 11, batches: 800, num_examples: 51200, 15875.6 samples/sec, epoch time so far: 0:00:03.225068\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:19 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.047 mean_absolute_error: 0.161 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:20 INFO 140033525749568] Epoch: 11, batches: 900, num_examples: 57600, 15882.0 samples/sec, epoch time so far: 0:00:03.626741\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:20 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.047 mean_absolute_error: 0.162 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:20 INFO 140033525749568] Epoch: 11, batches: 1000, num_examples: 64000, 15895.7 samples/sec, epoch time so far: 0:00:04.026256\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:20 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.047 mean_absolute_error: 0.162 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:20 INFO 140033525749568] Epoch: 11, batches: 1100, num_examples: 70400, 15892.7 samples/sec, epoch time so far: 0:00:04.429718\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:20 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.047 mean_absolute_error: 0.162 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:21 INFO 140033525749568] Epoch: 11, batches: 1200, num_examples: 76800, 15874.4 samples/sec, epoch time so far: 0:00:04.837986\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:21 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.047 mean_absolute_error: 0.162 \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/17/2018 14:58:21 INFO 140033525749568] Epoch: 11, batches: 1300, num_examples: 83200, 15879.2 samples/sec, epoch time so far: 0:00:05.239572\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:21 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.047 mean_absolute_error: 0.162 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] Epoch: 11, batches: 1400, num_examples: 89600, 15890.7 samples/sec, epoch time so far: 0:00:05.638528\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.047 mean_absolute_error: 0.162 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] Completed Epoch: 11, time taken: 0:00:05.702668\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] Epoch 11 Training metrics:   mean_squared_error: 0.047 mean_absolute_error: 0.162 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] #quality_metric: host=algo-1, epoch=11, train mean_squared_error <loss>=0.04691825388\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] Epoch 11 Validation metrics: mean_squared_error: 0.916 mean_absolute_error: 0.749 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] #quality_metric: host=algo-1, epoch=11, validation mean_squared_error <loss>=0.916135670768\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] patience losses: [0.91118532378931305, 0.91358408935972157, 0.91423374011709879]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] min patience losses: 0.911185323789\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] current loss: 0.916135670768\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] absolute loss difference: 0.00495034697894\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.49304962158203125, \"sum\": 0.49304962158203125, \"min\": 0.49304962158203125}, \"update.time\": {\"count\": 1, \"max\": 5890.7270431518555, \"sum\": 5890.7270431518555, \"min\": 5890.7270431518555}}, \"EndTime\": 1539788302.438527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788296.542537}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 16992, \"sum\": 16992.0, \"min\": 16992}, \"Total Records Seen\": {\"count\": 1, \"max\": 1087488, \"sum\": 1087488.0, \"min\": 1087488}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1539788302.438753, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 11}, \"StartTime\": 1539788296.547777}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15383.1916606 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] Epoch: 12, batches: 100, num_examples: 6400, 16026.5 samples/sec, epoch time so far: 0:00:00.399339\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:22 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.044 mean_absolute_error: 0.153 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:23 INFO 140033525749568] Epoch: 12, batches: 200, num_examples: 12800, 16037.9 samples/sec, epoch time so far: 0:00:00.798110\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:23 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.043 mean_absolute_error: 0.152 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:23 INFO 140033525749568] Epoch: 12, batches: 300, num_examples: 19200, 15978.3 samples/sec, epoch time so far: 0:00:01.201627\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:23 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.043 mean_absolute_error: 0.152 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:24 INFO 140033525749568] Epoch: 12, batches: 400, num_examples: 25600, 15977.1 samples/sec, epoch time so far: 0:00:01.602295\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:24 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.042 mean_absolute_error: 0.151 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:24 INFO 140033525749568] Epoch: 12, batches: 500, num_examples: 32000, 15974.3 samples/sec, epoch time so far: 0:00:02.003220\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:24 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.042 mean_absolute_error: 0.151 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:24 INFO 140033525749568] Epoch: 12, batches: 600, num_examples: 38400, 15977.2 samples/sec, epoch time so far: 0:00:02.403429\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:24 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.042 mean_absolute_error: 0.150 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:25 INFO 140033525749568] Epoch: 12, batches: 700, num_examples: 44800, 15971.5 samples/sec, epoch time so far: 0:00:02.804993\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:25 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.041 mean_absolute_error: 0.149 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:25 INFO 140033525749568] Epoch: 12, batches: 800, num_examples: 51200, 15948.5 samples/sec, epoch time so far: 0:00:03.210331\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:25 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.041 mean_absolute_error: 0.148 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:26 INFO 140033525749568] Epoch: 12, batches: 900, num_examples: 57600, 15950.3 samples/sec, epoch time so far: 0:00:03.611214\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:26 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.041 mean_absolute_error: 0.148 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:26 INFO 140033525749568] Epoch: 12, batches: 1000, num_examples: 64000, 15955.1 samples/sec, epoch time so far: 0:00:04.011252\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:26 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.041 mean_absolute_error: 0.148 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:26 INFO 140033525749568] Epoch: 12, batches: 1100, num_examples: 70400, 15960.9 samples/sec, epoch time so far: 0:00:04.410771\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:26 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.041 mean_absolute_error: 0.148 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:27 INFO 140033525749568] Epoch: 12, batches: 1200, num_examples: 76800, 15961.7 samples/sec, epoch time so far: 0:00:04.811506\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:27 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.041 mean_absolute_error: 0.148 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:27 INFO 140033525749568] Epoch: 12, batches: 1300, num_examples: 83200, 15951.3 samples/sec, epoch time so far: 0:00:05.215885\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:27 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.040 mean_absolute_error: 0.147 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] Epoch: 12, batches: 1400, num_examples: 89600, 15951.0 samples/sec, epoch time so far: 0:00:05.617189\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] #011Training metrics: mean_squared_error: 0.040 mean_absolute_error: 0.147 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] Completed Epoch: 12, time taken: 0:00:05.681792\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] Epoch 12 Training metrics:   mean_squared_error: 0.040 mean_absolute_error: 0.147 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] #quality_metric: host=algo-1, epoch=12, train mean_squared_error <loss>=0.0404413548393\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] Epoch 12 Validation metrics: mean_squared_error: 0.909 mean_absolute_error: 0.745 \u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] #quality_metric: host=algo-1, epoch=12, validation mean_squared_error <loss>=0.908640634772\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] patience losses: [0.91358408935972157, 0.91423374011709879, 0.91613567076824809]\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] min patience losses: 0.91358408936\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] current loss: 0.908640634772\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] absolute loss difference: 0.00494345458778\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] Bad epoch: loss has not improved (enough). Bad count:4\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] Early stopping criterion met! Stopping training at epoch: 12\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 2.7730464935302734, \"sum\": 2.7730464935302734, \"min\": 2.7730464935302734}, \"update.time\": {\"count\": 1, \"max\": 5872.115850448608, \"sum\": 5872.115850448608, \"min\": 5872.115850448608}}, \"EndTime\": 1539788308.316059, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788302.438604}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1416, \"sum\": 1416.0, \"min\": 1416}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Total Batches Seen\": {\"count\": 1, \"max\": 18408, \"sum\": 18408.0, \"min\": 18408}, \"Total Records Seen\": {\"count\": 1, \"max\": 1178112, \"sum\": 1178112.0, \"min\": 1178112}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 90624, \"sum\": 90624.0, \"min\": 90624}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1539788308.316406, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 12}, \"StartTime\": 1539788302.44392}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] #throughput_metric: host=algo-1, train throughput=15431.5790384 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 WARNING 140033525749568] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] Best model based on epoch 12. Best loss: 0.909\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 0.9179115295410156, \"sum\": 0.9179115295410156, \"min\": 0.9179115295410156}}, \"EndTime\": 1539788308.317697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788308.31615}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] Saved checkpoint to \"/tmp/tmpKCAI0R/state-0001.params\"\u001b[0m\n",
      "\u001b[31m[10/17/2018 14:58:28 INFO 140033525749568] Test data is not provided.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 82730.58295249939, \"sum\": 82730.58295249939, \"min\": 82730.58295249939}, \"model.serialize.time\": {\"count\": 1, \"max\": 72.45993614196777, \"sum\": 72.45993614196777, \"min\": 72.45993614196777}, \"setuptime\": {\"count\": 1, \"max\": 55.81498146057129, \"sum\": 55.81498146057129, \"min\": 55.81498146057129}}, \"EndTime\": 1539788308.391332, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539788308.317751}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-10-17 14:58:35 Uploading - Uploading generated training model\n",
      "2018-10-17 14:58:35 Completed - Training job completed\n",
      "Billable seconds: 185\n"
     ]
    }
   ],
   "source": [
    "## get estimator\n",
    "regressor = sagemaker.estimator.Estimator(container,\n",
    "                                          role, \n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.p2.xlarge',\n",
    "                                          output_path=output_path,\n",
    "                                          sagemaker_session=sess)\n",
    "\n",
    "## set hyperparameters\n",
    "regressor.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "## train the model\n",
    "regressor.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen that we can upload train (validation) data through the input data channel, and the algorithm will print out train (validation) metric during training. In addition, the algorithm uses the validation metric to perform early stopping. \n",
    "\n",
    "What if we want to send additional unlabeled data to the algorithm and get predictions from the trained model?\n",
    "This step is called *inference* in the Sagemaker framework. Next, we demonstrate how use a trained model to perform inference on unseen data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference using trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "\n",
    "# create a model using the trained algorithm\n",
    "regression_model = regressor.create_model(\n",
    "                        serializer=json_serializer,\n",
    "                        deserializer=json_deserializer,\n",
    "                        content_type='application/json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: object2vec-2018-10-17-14-58-53-705\n",
      "INFO:sagemaker:Creating endpoint with name object2vec-2018-10-17-14-58-53-705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "# deploy the model\n",
    "predictor = regression_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we send the validation data (without labels) to the deployed endpoint for inference. We see that the resulting prediction error we get from inference is the same as the best validation error from the console output (up to floating point error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error on validation set is 0.910\n"
     ]
    }
   ],
   "source": [
    "# Send data to the endpoint to get predictions\n",
    "prediction = predictor.predict(valid_r_data)\n",
    "\n",
    "print(\"The mean squared error on validation set is %.3f\" %get_mse_loss(prediction, valid_r_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended to always delete the endpoints used for hosting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: object2vec-2018-10-17-14-58-53-705\n"
     ]
    }
   ],
   "source": [
    "## clean up\n",
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_accuracy(res, labels, thres):\n",
    "    if type(res) is dict:\n",
    "        res = res['predictions']\n",
    "    assert len(res)==len(labels), 'result and label length mismatch!'\n",
    "    accuracy = 0\n",
    "    for row, label in zip(res, labels):\n",
    "        if type(row) is dict:\n",
    "            if row['scores'][1] > thres:\n",
    "                prediction = 1\n",
    "            else: \n",
    "                prediction = 0\n",
    "            if label > thres:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            accuracy += 1-(prediction - label)**2\n",
    "    return accuracy / float(len(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We upload the binarized datasets for classification task to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded data to s3://ntm-local-us-west-2/object2vec/movielens/small/recommendation/train/train_c.jsonl\n",
      "Uploaded data to s3://ntm-local-us-west-2/object2vec/movielens/small/recommendation/validation/validation_c.jsonl\n"
     ]
    }
   ],
   "source": [
    "for data_name in ['train', 'validation']:\n",
    "    fname = '{}_c.jsonl'.format(data_name)\n",
    "    pre_key = os.path.join(input_prefix, 'recommendation', f\"{data_name}\")\n",
    "    data_path = os.path.join('s3://', bucket, pre_key, fname)\n",
    "    s3_client.upload_file(fname, bucket, os.path.join(pre_key, fname))\n",
    "    input_paths[data_name] = s3_input(data_path, distribution='ShardedByS3Key', content_type='application/jsonlines')\n",
    "    print('Uploaded data to {}'.format(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already get the algorithm image from the regression task, we can directly start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import s3_input\n",
    "\n",
    "hyperparameters_c = {\n",
    "    \"_kvstore\": \"device\",\n",
    "    \"_num_gpus\": \"auto\",\n",
    "    \"_num_kv_servers\": \"auto\",\n",
    "    \"bucket_width\": 0,\n",
    "    \"early_stopping_patience\": 3, \n",
    "    \"early_stopping_tolerance\": 0.01,\n",
    "    \"enc0_cnn_filter_width\": 3,\n",
    "    \"enc0_layers\": \"auto\",\n",
    "    \"enc0_max_seq_len\": 1,\n",
    "    \"enc0_network\": \"pooled_embedding\",\n",
    "    \"enc0_token_embedding_dim\": 300,\n",
    "    \"enc0_vocab_size\": 944,\n",
    "    \"enc1_cnn_filter_width\": 3,\n",
    "    \"enc1_layers\": \"auto\",\n",
    "    \"enc1_max_seq_len\": 1,\n",
    "    \"enc1_network\": \"pooled_embedding\",\n",
    "    \"enc1_token_embedding_dim\": 300,\n",
    "    \"enc1_vocab_size\": 1684,\n",
    "    \"enc_dim\": 2048,\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"mini_batch_size\": 2048,\n",
    "    \"mlp_activation\": \"relu\",\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"mlp_layers\": 1,\n",
    "    \"num_classes\": 2,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"output_layer\": \"softmax\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: object2vec-2018-10-17-15-09-17-422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-17 15:09:17 Starting - Starting the training job...\n",
      "2018-10-17 15:09:19 Starting - Launching requested ML instances...\n",
      "2018-10-17 15:10:18 Starting - Preparing the instances for training......\n",
      "2018-10-17 15:11:16 Downloading - Downloading input data\n",
      "2018-10-17 15:11:16 Training - Downloading the training image......\n",
      "2018-10-17 15:12:07 Training - Training image download completed. Training in progress.\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'output_layer': u'softmax', u'enc1:freeze_pretrained_embedding': u'true', u'enc1:vocab_file': u'', u'enc0:vocab_file': u'', u'epochs': 20, u'mlp_dim': 512, u'enc0:token_embedding_dim': 300, u'enc0:network': u'hcnn', u'_num_kv_servers': u'auto', u'mlp_layers': 2, u'enc0:layers': u'auto', u'weight_decay': 0, u'enc1:layers': u'auto', u'learning_rate': 0.0004, u'negative_sampling_rate': 0, u'num_classes': 2, u'enc0:cnn_filter_width': 3, u'early_stopping_patience': 3, u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': 0.01, u'dropout': 0, u'bucket_width': 0, u'enc_dim': 4096, u'enc1:cnn_filter_width': 3, u'enc0:freeze_pretrained_embedding': u'true', u'mini_batch_size': 32, u'enc1:network': u'enc0', u'enc1:pretrained_embedding_file': u'', u'enc1:token_embedding_dim': 300, u'_num_gpus': u'auto', u'mlp_activation': u'linear', u'_kvstore': u'auto_gpu', u'enc0:pretrained_embedding_file': u''}\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'output_layer': u'softmax', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0:token_embedding_dim': u'300', u'enc0:network': u'pooled_embedding', u'_num_kv_servers': u'auto', u'mlp_layers': u'1', u'enc0:layers': u'auto', u'enc1:layers': u'auto', u'early_stopping_tolerance': u'0.01', u'enc0:cnn_filter_width': u'3', u'early_stopping_patience': u'3', u'enc0:vocab_size': u'944', u'optimizer': u'adam', u'enc0:max_seq_len': u'1', u'learning_rate': u'0.001', u'bucket_width': u'0', u'enc_dim': u'2048', u'enc1:cnn_filter_width': u'3', u'mini_batch_size': u'2048', u'enc1:network': u'pooled_embedding', u'num_classes': u'2', u'enc1:token_embedding_dim': u'300', u'_num_gpus': u'auto', u'enc1:max_seq_len': u'1', u'mlp_activation': u'relu', u'enc1:vocab_size': u'1684', u'_kvstore': u'device'}\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] Final configuration: {u'output_layer': u'softmax', u'enc1:freeze_pretrained_embedding': u'true', u'enc1:vocab_file': u'', u'enc0:vocab_file': u'', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0:token_embedding_dim': u'300', u'enc0:network': u'pooled_embedding', u'_num_kv_servers': u'auto', u'mlp_layers': u'1', u'enc0:layers': u'auto', u'weight_decay': 0, u'enc1:layers': u'auto', u'learning_rate': u'0.001', u'enc0:max_seq_len': u'1', u'negative_sampling_rate': 0, u'num_classes': u'2', u'enc0:cnn_filter_width': u'3', u'early_stopping_patience': u'3', u'enc0:vocab_size': u'944', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'2048', u'enc1:cnn_filter_width': u'3', u'enc0:freeze_pretrained_embedding': u'true', u'mini_batch_size': u'2048', u'enc1:network': u'pooled_embedding', u'enc1:pretrained_embedding_file': u'', u'enc1:token_embedding_dim': u'300', u'_num_gpus': u'auto', u'enc1:max_seq_len': u'1', u'mlp_activation': u'relu', u'enc1:vocab_size': u'1684', u'_kvstore': u'device', u'enc0:pretrained_embedding_file': u''}\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] Using default worker.\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] create_iter params {u'output_layer': u'softmax', u'enc1:freeze_pretrained_embedding': u'true', u'enc1:vocab_file': u'', u'enc0:vocab_file': u'', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0:token_embedding_dim': u'300', u'enc0:network': u'pooled_embedding', u'_num_kv_servers': u'auto', u'mlp_layers': u'1', u'enc0:layers': u'auto', u'weight_decay': 0, u'enc1:layers': u'auto', u'learning_rate': u'0.001', u'enc0:max_seq_len': u'1', u'negative_sampling_rate': 0, u'num_classes': u'2', u'enc0:cnn_filter_width': u'3', u'early_stopping_patience': u'3', u'enc0:vocab_size': u'944', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'2048', u'enc1:cnn_filter_width': u'3', u'enc0:freeze_pretrained_embedding': u'true', u'mini_batch_size': u'2048', u'enc1:network': u'pooled_embedding', u'enc1:pretrained_embedding_file': u'', u'enc1:token_embedding_dim': u'300', u'_num_gpus': u'auto', u'enc1:max_seq_len': u'1', u'mlp_activation': u'relu', u'enc1:vocab_size': u'1684', u'_kvstore': u'device', u'enc0:pretrained_embedding_file': u''}\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] create_iter content_params {}\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] Config: {'epochs': 20, 'mini_batch_size': 2048, 'optimizer': 'adam', 'output_layer': 'softmax', 'mlp_dim': 1024, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 2048, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] use bucketing: False\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:10 INFO 140081017829184] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:11 INFO 140081017829184] Source words: 90570\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:11 INFO 140081017829184] Target words: 90570\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:11 INFO 140081017829184] Total: 90570 samples in 1 buckets\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:11 INFO 140081017829184] Bucket of (1, 1) : 90570 samples in 44 batches of 2048, approx 2048.0 words/batch\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:11 INFO 140081017829184] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:11 INFO 140081017829184] fill up mode: replicate\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:11 INFO 140081017829184] \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Replicating 1590 random sentences from bucket (1, 1) to size it to multiple of 2048\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Bucket batch sizes: [BucketBatchSize(batch_size=2048, average_words_per_batch=2048)]\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] create_iter params {u'output_layer': u'softmax', u'enc1:freeze_pretrained_embedding': u'true', u'enc1:vocab_file': u'', u'enc0:vocab_file': u'', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0:token_embedding_dim': u'300', u'enc0:network': u'pooled_embedding', u'_num_kv_servers': u'auto', u'mlp_layers': u'1', u'enc0:layers': u'auto', u'weight_decay': 0, u'enc1:layers': u'auto', u'learning_rate': u'0.001', u'enc0:max_seq_len': u'1', u'negative_sampling_rate': 0, u'num_classes': u'2', u'enc0:cnn_filter_width': u'3', u'early_stopping_patience': u'3', u'enc0:vocab_size': u'944', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'2048', u'enc1:cnn_filter_width': u'3', u'enc0:freeze_pretrained_embedding': u'true', u'mini_batch_size': u'2048', u'enc1:network': u'pooled_embedding', u'enc1:pretrained_embedding_file': u'', u'enc1:token_embedding_dim': u'300', u'_num_gpus': u'auto', u'enc1:max_seq_len': u'1', u'mlp_activation': u'relu', u'enc1:vocab_size': u'1684', u'_kvstore': u'device', u'enc0:pretrained_embedding_file': u''}\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] create_iter content_params {}\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Config: {'epochs': 20, 'mini_batch_size': 2048, 'optimizer': 'adam', 'output_layer': 'softmax', 'mlp_dim': 1024, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 2048, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] use bucketing: False\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Source words: 9430\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Target words: 9430\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Total: 9430 samples in 1 buckets\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Bucket of (1, 1) : 9430 samples in 4 batches of 2048, approx 2048.0 words/batch\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] fill up mode: replicate\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Replicating 810 random sentences from bucket (1, 1) to size it to multiple of 2048\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Parameters of encoders: [{u'layers': u'auto', u'vocab_size': u'944', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}, {u'layers': u'auto', u'vocab_size': u'1684', u'network': u'pooled_embedding', u'vocab_file': u'', u'cnn_filter_width': u'3', u'token_embedding_dim': u'300', u'max_seq_len': u'1', u'freeze_pretrained_embedding': u'true', u'pretrained_embedding_file': u''}]\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 2048 vs 300. Setting token embedding dim to be 2048\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Encoder configs: [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}]\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Config: {'epochs': 20, 'mini_batch_size': 2048, 'optimizer': 'adam', 'output_layer': 'softmax', 'mlp_dim': 1024, 'early_stopping_tolerance': 0.01, 'dropout': 0.0, 'bucket_width': 0, 'enc_dim': 2048, 'early_stopping_patience': 3, 'learning_rate': 0.001, 'max_seq_lens': [1, 1], 'enc_configs': [{'vocab_size': 944, 'enc_index': 0, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}, {'vocab_size': 1684, 'enc_index': 1, 'pretrained_embedding_file_path': None, 'vocab_dict': None, 'token_embedding_dim': 2048, 'vocab_file': '', 'freeze_pretrained_embedding': True, 'num_layers': <bound method ABCMeta.default_num_layers of <class 'algorithm.config.pooled_embedding_encoder_config.PooledEmbeddingEncoderConfig'>>, 'dropout': 0.0, 'pretrained_embedding_file': ''}], 'mlp_layers': 1, 'weight_decay': 0.0, 'mlp_activation': 'relu', 'num_classes': 2}\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Creating new state\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] params {u'output_layer': u'softmax', u'enc1:freeze_pretrained_embedding': u'true', u'enc1:vocab_file': u'', u'enc0:vocab_file': u'', u'epochs': u'20', u'mlp_dim': u'1024', u'enc0:token_embedding_dim': u'300', u'enc0:network': u'pooled_embedding', u'_num_kv_servers': u'auto', u'mlp_layers': u'1', u'enc0:layers': u'auto', u'weight_decay': 0, u'enc1:layers': u'auto', u'learning_rate': u'0.001', u'enc0:max_seq_len': u'1', u'negative_sampling_rate': 0, u'num_classes': u'2', u'enc0:cnn_filter_width': u'3', u'early_stopping_patience': u'3', u'enc0:vocab_size': u'944', u'optimizer': u'adam', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.01', u'dropout': 0, u'bucket_width': u'0', u'enc_dim': u'2048', 'default_bucket_key': (1, 1), u'enc1:cnn_filter_width': u'3', u'enc0:freeze_pretrained_embedding': u'true', u'mini_batch_size': u'2048', u'enc1:network': u'pooled_embedding', u'enc1:pretrained_embedding_file': u'', u'enc1:token_embedding_dim': u'300', u'_num_gpus': u'auto', u'enc1:max_seq_len': u'1', u'mlp_activation': u'relu', u'enc1:vocab_size': u'1684', u'_kvstore': u'device', u'enc0:pretrained_embedding_file': u''}\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] nvidia-smi took: 0.151036977768 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] context [gpu(0)]\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Create Store: device\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[31m========================================================================================================================\u001b[0m\n",
      "\u001b[31msource(null)                                        1                       0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31membed_0(Embedding)                                  1x2048                  0           source                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_not_equal_scalar0(_not_equal_scalar)               1                       0           source                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mreshape0(Reshape)                                   1x1                     0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_mul0(broadcast_mul)                       1x2048                  0           embed_0                         \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum0(sum)                                           2048                    0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum1(sum)                                           1                       0           reshape0                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mzeros_like0(zeros_like)                             1                       0           sum1                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_equal0(_equal)                                     1                       0           sum1                            \n",
      "                                                                                        zeros_like0                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_plus0(elemwise_add)                                1                       0           sum1                            \n",
      "                                                                                        _equal0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_div0(broadcast_div)                       2048                    0           sum0                            \n",
      "                                                                                        _plus0                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout0(Dropout)                                   2048                    0           broadcast_div0                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31membed_1(Embedding)                                  1x2048                  0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_not_equal_scalar1(_not_equal_scalar)               1                       0                                           \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mreshape1(Reshape)                                   1x1                     0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_mul1(broadcast_mul)                       1x2048                  0           embed_1                         \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum2(sum)                                           2048                    0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msum3(sum)                                           1                       0           reshape1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mzeros_like1(zeros_like)                             1                       0           sum3                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_equal1(_equal)                                     1                       0           sum3                            \n",
      "                                                                                        zeros_like1                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_plus1(elemwise_add)                                1                       0           sum3                            \n",
      "                                                                                        _equal1                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mbroadcast_div1(broadcast_div)                       2048                    0           sum2                            \n",
      "                                                                                        _plus1                          \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout1(Dropout)                                   2048                    0           broadcast_div1                  \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_mul0(elemwise_mul)                                 2048                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m_minus0(elemwise_sub)                               2048                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mabs0(abs)                                           2048                    0           _minus0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconcat0(Concat)                                     8192                    0           _mul0                           \n",
      "                                                                                        dropout0                        \n",
      "                                                                                        dropout1                        \n",
      "                                                                                        abs0                            \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mmlp_fc0(FullyConnected)                             1024                    8389632     concat0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation0(Activation)                             1024                    0           mlp_fc0                         \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout2(Dropout)                                   1024                    0           activation0                     \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31moutput_layer(FullyConnected)                        2                       2050        dropout2                        \u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mout_layer(SoftmaxOutput)                            2                       0           output_layer                    \u001b[0m\n",
      "\u001b[31m========================================================================================================================\u001b[0m\n",
      "\u001b[31mTotal params: 8391682\u001b[0m\n",
      "\u001b[31m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] fixed_param_names: []\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:12 INFO 140081017829184] Initialized BucketingPlus Module\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[10/17/2018 15:12:15 INFO 140081017829184] arg_params keys for module initialization: []\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:15 INFO 140081017829184] all params:['output_layer_weight', 'mlp_fc0_weight', 'mlp_fc0_bias', 'output_layer_bias', 'embed_1_weight', 'embed_0_weight']\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 3527.2140502929688, \"sum\": 3527.2140502929688, \"min\": 3527.2140502929688}}, \"EndTime\": 1539789135.778064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539789130.157843}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1539789135.778266, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539789135.77821}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:20 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:20 INFO 140081017829184] Completed Epoch: 0, time taken: 0:00:04.044515\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:20 INFO 140081017829184] Epoch 0 Training metrics:   perplexity: 1.846 cross_entropy: 0.613 accuracy: 0.659 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:20 INFO 140081017829184] #quality_metric: host=algo-1, epoch=0, train cross_entropy <loss>=0.613023228116\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:20 INFO 140081017829184] #quality_metric: host=algo-1, epoch=0, train accuracy <score>=0.659299045139\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:20 INFO 140081017829184] Epoch 0 Validation metrics: perplexity: 1.792 cross_entropy: 0.583 accuracy: 0.697 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:20 INFO 140081017829184] #quality_metric: host=algo-1, epoch=0, validation cross_entropy <loss>=0.583112025261\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:20 INFO 140081017829184] #quality_metric: host=algo-1, epoch=0, validation accuracy <score>=0.69677734375\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:20 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}, \"early_stop.time\": {\"count\": 1, \"max\": 0.2701282501220703, \"sum\": 0.2701282501220703, \"min\": 0.2701282501220703}, \"update.time\": {\"count\": 1, \"max\": 4157.707929611206, \"sum\": 4157.707929611206, \"min\": 4157.707929611206}}, \"EndTime\": 1539789140.11745, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539789135.77816}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:20 INFO 140081017829184] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Total Records Seen\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1539789140.117714, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 0}, \"StartTime\": 1539789135.95972}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:20 INFO 140081017829184] #throughput_metric: host=algo-1, train throughput=22163.660897 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:24 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:24 INFO 140081017829184] Completed Epoch: 1, time taken: 0:00:03.994797\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:24 INFO 140081017829184] Epoch 1 Training metrics:   perplexity: 1.722 cross_entropy: 0.543 accuracy: 0.723 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:24 INFO 140081017829184] #quality_metric: host=algo-1, epoch=1, train cross_entropy <loss>=0.543470538987\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:24 INFO 140081017829184] #quality_metric: host=algo-1, epoch=1, train accuracy <score>=0.722547743056\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:24 INFO 140081017829184] Epoch 1 Validation metrics: perplexity: 1.772 cross_entropy: 0.572 accuracy: 0.706 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:24 INFO 140081017829184] #quality_metric: host=algo-1, epoch=1, validation cross_entropy <loss>=0.572206604481\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:24 INFO 140081017829184] #quality_metric: host=algo-1, epoch=1, validation accuracy <score>=0.70556640625\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:24 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 3.6301612854003906, \"sum\": 3.6301612854003906, \"min\": 3.6301612854003906}, \"update.time\": {\"count\": 1, \"max\": 4110.851049423218, \"sum\": 4110.851049423218, \"min\": 4110.851049423218}}, \"EndTime\": 1539789144.301327, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539789140.117528}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:24 INFO 140081017829184] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 90, \"sum\": 90.0, \"min\": 90}, \"Total Records Seen\": {\"count\": 1, \"max\": 184320, \"sum\": 184320.0, \"min\": 184320}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1539789144.301698, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 1}, \"StartTime\": 1539789140.190455}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:24 INFO 140081017829184] #throughput_metric: host=algo-1, train throughput=22415.7162443 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:28 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:28 INFO 140081017829184] Completed Epoch: 2, time taken: 0:00:03.985168\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:28 INFO 140081017829184] Epoch 2 Training metrics:   perplexity: 1.654 cross_entropy: 0.503 accuracy: 0.752 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:28 INFO 140081017829184] #quality_metric: host=algo-1, epoch=2, train cross_entropy <loss>=0.503356409073\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:28 INFO 140081017829184] #quality_metric: host=algo-1, epoch=2, train accuracy <score>=0.752018229167\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:28 INFO 140081017829184] Epoch 2 Validation metrics: perplexity: 1.804 cross_entropy: 0.590 accuracy: 0.693 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:28 INFO 140081017829184] #quality_metric: host=algo-1, epoch=2, validation cross_entropy <loss>=0.589915168285\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:28 INFO 140081017829184] #quality_metric: host=algo-1, epoch=2, validation accuracy <score>=0.69287109375\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:28 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.031948089599609375, \"sum\": 0.031948089599609375, \"min\": 0.031948089599609375}, \"update.time\": {\"count\": 1, \"max\": 4097.675085067749, \"sum\": 4097.675085067749, \"min\": 4097.675085067749}}, \"EndTime\": 1539789148.490607, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539789144.301457}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:28 INFO 140081017829184] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 135, \"sum\": 135.0, \"min\": 135}, \"Total Records Seen\": {\"count\": 1, \"max\": 276480, \"sum\": 276480.0, \"min\": 276480}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1539789148.490872, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 2}, \"StartTime\": 1539789144.392902}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:28 INFO 140081017829184] #throughput_metric: host=algo-1, train throughput=22488.2782347 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] Completed Epoch: 3, time taken: 0:00:04.001541\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] Epoch 3 Training metrics:   perplexity: 1.377 cross_entropy: 0.320 accuracy: 0.869 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] #quality_metric: host=algo-1, epoch=3, train cross_entropy <loss>=0.319865391652\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] #quality_metric: host=algo-1, epoch=3, train accuracy <score>=0.868641493056\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] Epoch 3 Validation metrics: perplexity: 2.151 cross_entropy: 0.766 accuracy: 0.672 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] #quality_metric: host=algo-1, epoch=3, validation cross_entropy <loss>=0.765929961205\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] #quality_metric: host=algo-1, epoch=3, validation accuracy <score>=0.6720703125\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] patience losses: [0.58311202526092532, 0.57220660448074345, 0.58991516828536983]\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] min patience losses: 0.572206604481\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] current loss: 0.765929961205\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] absolute loss difference: 0.193723356724\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.47707557678222656, \"sum\": 0.47707557678222656, \"min\": 0.47707557678222656}, \"update.time\": {\"count\": 1, \"max\": 4114.729881286621, \"sum\": 4114.729881286621, \"min\": 4114.729881286621}}, \"EndTime\": 1539789152.610382, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539789148.490693}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 180, \"sum\": 180.0, \"min\": 180}, \"Total Records Seen\": {\"count\": 1, \"max\": 368640, \"sum\": 368640.0, \"min\": 368640}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1539789152.610619, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 3}, \"StartTime\": 1539789148.495629}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:32 INFO 140081017829184] #throughput_metric: host=algo-1, train throughput=22395.5459923 records/second\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-10-17 15:12:49 Uploading - Uploading generated training model\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] Completed Epoch: 4, time taken: 0:00:04.005284\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] Epoch 4 Training metrics:   perplexity: 1.080 cross_entropy: 0.077 accuracy: 0.979 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] #quality_metric: host=algo-1, epoch=4, train cross_entropy <loss>=0.0771016137467\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] #quality_metric: host=algo-1, epoch=4, train accuracy <score>=0.979286024306\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] Epoch 4 Validation metrics: perplexity: 2.553 cross_entropy: 0.937 accuracy: 0.693 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] #quality_metric: host=algo-1, epoch=4, validation cross_entropy <loss>=0.937205457687\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] #quality_metric: host=algo-1, epoch=4, validation accuracy <score>=0.693359375\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] patience losses: [0.57220660448074345, 0.58991516828536983, 0.76592996120452883]\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] min patience losses: 0.572206604481\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] current loss: 0.937205457687\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] absolute loss difference: 0.364998853207\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.4940032958984375, \"sum\": 0.4940032958984375, \"min\": 0.4940032958984375}, \"update.time\": {\"count\": 1, \"max\": 4118.0260181427, \"sum\": 4118.0260181427, \"min\": 4118.0260181427}}, \"EndTime\": 1539789156.733356, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539789152.610471}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 225, \"sum\": 225.0, \"min\": 225}, \"Total Records Seen\": {\"count\": 1, \"max\": 460800, \"sum\": 460800.0, \"min\": 460800}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1539789156.733632, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 4}, \"StartTime\": 1539789152.615307}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:36 INFO 140081017829184] #throughput_metric: host=algo-1, train throughput=22377.3938517 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] Completed Epoch: 5, time taken: 0:00:04.013476\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] Epoch 5 Training metrics:   perplexity: 1.013 cross_entropy: 0.013 accuracy: 0.999 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] #quality_metric: host=algo-1, epoch=5, train cross_entropy <loss>=0.0129576773693\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] #quality_metric: host=algo-1, epoch=5, train accuracy <score>=0.998643663194\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] Epoch 5 Validation metrics: perplexity: 2.839 cross_entropy: 1.043 accuracy: 0.696 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] #quality_metric: host=algo-1, epoch=5, validation cross_entropy <loss>=1.04336614609\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] #quality_metric: host=algo-1, epoch=5, validation accuracy <score>=0.6962890625\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] patience losses: [0.58991516828536983, 0.76592996120452883, 0.93720545768737795]\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] min patience losses: 0.589915168285\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] current loss: 1.04336614609\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] absolute loss difference: 0.453450977802\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.4830360412597656, \"sum\": 0.4830360412597656, \"min\": 0.4830360412597656}, \"update.time\": {\"count\": 1, \"max\": 4128.73911857605, \"sum\": 4128.73911857605, \"min\": 4128.73911857605}}, \"EndTime\": 1539789160.867122, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539789156.733455}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 270, \"sum\": 270.0, \"min\": 270}, \"Total Records Seen\": {\"count\": 1, \"max\": 552960, \"sum\": 552960.0, \"min\": 552960}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1539789160.867377, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 5}, \"StartTime\": 1539789156.738361}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:40 INFO 140081017829184] #throughput_metric: host=algo-1, train throughput=22319.4181421 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] Completed Epoch: 6, time taken: 0:00:04.014449\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] Epoch 6 Training metrics:   perplexity: 1.003 cross_entropy: 0.003 accuracy: 1.000 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] #quality_metric: host=algo-1, epoch=6, train cross_entropy <loss>=0.00294981663529\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] #quality_metric: host=algo-1, epoch=6, train accuracy <score>=0.999956597222\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] Epoch 6 Validation metrics: perplexity: 3.041 cross_entropy: 1.112 accuracy: 0.699 \u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] #quality_metric: host=algo-1, epoch=6, validation cross_entropy <loss>=1.11228322983\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] #quality_metric: host=algo-1, epoch=6, validation accuracy <score>=0.6990234375\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] **************\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] patience losses: [0.76592996120452883, 0.93720545768737795, 1.0433661460876464]\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] min patience losses: 0.765929961205\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] current loss: 1.11228322983\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] absolute loss difference: 0.346353268623\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] Bad epoch: loss has not improved (enough). Bad count:4\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] Early stopping criterion met! Stopping training at epoch: 6\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"early_stop.time\": {\"count\": 1, \"max\": 0.6630420684814453, \"sum\": 0.6630420684814453, \"min\": 0.6630420684814453}, \"update.time\": {\"count\": 1, \"max\": 4127.494096755981, \"sum\": 4127.494096755981, \"min\": 4127.494096755981}}, \"EndTime\": 1539789164.999606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539789160.867205}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:44 INFO 140081017829184] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 45, \"sum\": 45.0, \"min\": 45}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Total Batches Seen\": {\"count\": 1, \"max\": 315, \"sum\": 315.0, \"min\": 315}, \"Total Records Seen\": {\"count\": 1, \"max\": 645120, \"sum\": 645120.0, \"min\": 645120}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 92160, \"sum\": 92160.0, \"min\": 92160}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1539789164.999964, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\", \"epoch\": 6}, \"StartTime\": 1539789160.872087}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:45 INFO 140081017829184] #throughput_metric: host=algo-1, train throughput=22325.5761241 records/second\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:45 WARNING 140081017829184] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:45 INFO 140081017829184] Best model based on epoch 1. Best loss: 0.572\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 0.9310245513916016, \"sum\": 0.9310245513916016, \"min\": 0.9310245513916016}}, \"EndTime\": 1539789165.001234, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539789164.999701}\n",
      "\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:45 INFO 140081017829184] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:45 INFO 140081017829184] Saved checkpoint to \"/tmp/tmpjBZ8aM/state-0001.params\"\u001b[0m\n",
      "\u001b[31m[10/17/2018 15:12:45 INFO 140081017829184] Test data is not provided.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 35152.99987792969, \"sum\": 35152.99987792969, \"min\": 35152.99987792969}, \"model.serialize.time\": {\"count\": 1, \"max\": 212.25905418395996, \"sum\": 212.25905418395996, \"min\": 212.25905418395996}, \"setuptime\": {\"count\": 1, \"max\": 57.87491798400879, \"sum\": 57.87491798400879, \"min\": 57.87491798400879}}, \"EndTime\": 1539789165.217732, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"ObjectToVec\"}, \"StartTime\": 1539789165.001285}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2018-10-17 15:12:59 Completed - Training job completed\n",
      "Billable seconds: 112\n"
     ]
    }
   ],
   "source": [
    "## get estimator\n",
    "classifier = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.p2.xlarge',\n",
    "                                    output_path=output_path,\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "## set hyperparameters\n",
    "classifier.set_hyperparameters(**hyperparameters_c)\n",
    "\n",
    "## train, tune, and test the model\n",
    "classifier.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can create, deploy, and validate the model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: object2vec-2018-10-17-15-14-18-560\n",
      "INFO:sagemaker:Creating endpoint with name object2vec-2018-10-17-15-14-18-560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "classification_model = classifier.create_model(\n",
    "                        serializer=json_serializer,\n",
    "                        deserializer=json_deserializer,\n",
    "                        content_type='application/json')\n",
    "\n",
    "predictor_2 = classification_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the binarized validation set is 0.704\n"
     ]
    }
   ],
   "source": [
    "valid_c_data, valid_c_label = data_list_to_inference_format(copy.deepcopy(validation_data_list), \n",
    "                                                            label_thres=3, binarize=True)\n",
    "predictions = predictor_2.predict(valid_c_data)\n",
    "print(\"The accuracy on the binarized validation set is %.3f\" %get_class_accuracy(predictions, valid_c_label, 0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
